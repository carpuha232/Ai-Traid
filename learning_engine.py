"""
üß† –î–≤–∏–∂–æ–∫ –ø—Ä–æ–≥—Ä–µ—Å—Å–∏–≤–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –∞–≤—Ç–æ–Ω–æ–º–Ω–æ–π –Ω–µ–π—Ä–æ—Å–µ—Ç–∏
–£—á–∏—Ç—Å—è –Ω–∞ –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã—Ö —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞—Ö, –¥–æ—Å—Ç–∏–≥–∞–µ—Ç 70%+ –≤–∏–Ω—Ä–µ–π—Ç–∞, –ø–µ—Ä–µ—Ö–æ–¥–∏—Ç –∫ –º–µ–Ω—å—à–∏–º
"""

import pandas as pd
import numpy as np
import random
import time
import json
from datetime import datetime, timedelta
from typing import Dict, List, Tuple, Optional
import os

from neural_network import AutonomousNeuralNetwork
from data_loader import RawDataLoader

class ProgressiveLearningEngine:
    """–î–≤–∏–∂–æ–∫ –ø—Ä–æ–≥—Ä–µ—Å—Å–∏–≤–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –ø–æ —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞–º"""
    
    def __init__(self, initial_capital: float = 100.0):
        self.neural_network = AutonomousNeuralNetwork(initial_capital)
        self.data_loader = RawDataLoader()
        
        # –ö–æ–º–∏—Å—Å–∏–∏ –∑–∞ —Ç–æ—Ä–≥–æ–≤–ª—é —Ñ—å—é—á–µ—Ä—Å–∞–º–∏ Binance
        self.entry_fee = 0.0002  # 0.02% –∑–∞ –≤—Ö–æ–¥ –≤ –ø–æ–∑–∏—Ü–∏—é (maker)
        self.exit_fee = 0.0004   # 0.04% –∑–∞ –≤—ã—Ö–æ–¥ –∏–∑ –ø–æ–∑–∏—Ü–∏–∏ (taker)
        
        # –ü—Ä–æ–≥—Ä–µ—Å—Å–∏–≤–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –ø–æ —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞–º (–æ—Ç –±–æ–ª—å—à–µ–≥–æ –∫ –º–µ–Ω—å—à–µ–º—É)
        self.timeframe_progression = ['1M', '1w', '1d', '12h', '8h', '6h', '4h', '2h', '1h', '30m', '15m', '5m', '3m', '1m']
        self.current_timeframe_index = 0
        self.current_timeframe = self.timeframe_progression[0]
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—É—á–µ–Ω–∏—è - –£–õ–£–ß–®–ï–ù–ù–ê–Ø –í–ï–†–°–ò–Ø
        self.learning_config = {
            'target_win_rate': 0.55,  # –¶–µ–ª–µ–≤–æ–π –≤–∏–Ω—Ä–µ–π—Ç 55%+ (–±–æ–ª–µ–µ —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω–æ)
            'max_drawdown': 0.3,     # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø—Ä–æ—Å–∞–¥–∫–∞ 30%
            'cycles_per_timeframe': 999,  # –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏ –±–µ—Å–∫–æ–Ω–µ—á–Ω—ã–µ —Ü–∏–∫–ª—ã
            'trades_per_cycle': 50,      # –°–¥–µ–ª–æ–∫ –∑–∞ —Ü–∏–∫–ª
            'max_restarts': 999,         # –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏ –±–µ—Å–∫–æ–Ω–µ—á–Ω—ã–µ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∏
            'evaluation_cycles': 15,     # –û—Ü–µ–Ω–∫–∞ –∫–∞–∂–¥—ã–µ 15 —Ü–∏–∫–ª–æ–≤ (–±–æ–ª—å—à–µ –≤—Ä–µ–º–µ–Ω–∏ –Ω–∞ —Å—Ç–∞–±–∏–ª–∏–∑–∞—Ü–∏—é)
            'max_cycles_without_improvement': 100  # –ë–æ–ª—å—à–µ —Ü–∏–∫–ª–æ–≤ –±–µ–∑ —É–ª—É—á—à–µ–Ω–∏–π
        }
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ–±—É—á–µ–Ω–∏—è
        self.learning_history = []
        self.timeframe_history = []
        self.current_cycle = 0
        self.current_restart = 0
        self.best_performance = {
            'win_rate': 0.0,
            'total_profit': 0.0,
            'timeframe': '',
            'cycle': 0
        }
        
        # –°–æ—Å—Ç–æ—è–Ω–∏–µ –æ–±—É—á–µ–Ω–∏—è
        self.is_learning = False
        self.learning_start_time = None
    
    def start_progressive_learning(self):
        """–ó–∞–ø—É—Å–∫ –ë–ï–°–ö–û–ù–ï–ß–ù–û–ì–û –ø—Ä–æ–≥—Ä–µ—Å—Å–∏–≤–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –ø–æ —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞–º"""
        print("üöÄ –ó–ê–ü–£–°–ö –ë–ï–°–ö–û–ù–ï–ß–ù–û–ì–û –ü–†–û–ì–†–ï–°–°–ò–í–ù–û–ì–û –û–ë–£–ß–ï–ù–ò–Ø")
        print("=" * 60)
        print("üéØ –¶–µ–ª—å: –≤–∏–Ω—Ä–µ–π—Ç 55%+ –Ω–∞ –∫–∞–∂–¥–æ–º —Ç–∞–π–º—Ñ—Ä–µ–π–º–µ (–±–æ–ª–µ–µ —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω–æ)")
        print("üìà –ü—Ä–æ–≥—Ä–µ—Å—Å–∏—è: 1M ‚Üí 1w ‚Üí 1d ‚Üí 12h ‚Üí 8h ‚Üí 6h ‚Üí 4h ‚Üí 2h ‚Üí 1h ‚Üí 30m ‚Üí 15m ‚Üí 5m ‚Üí 3m ‚Üí 1m")
        print("üîÑ –ë–ï–°–ö–û–ù–ï–ß–ù–û–ï –û–ë–£–ß–ï–ù–ò–ï: –±–æ—Ç –±—É–¥–µ—Ç —É—á–∏—Ç—å—Å—è –¥–æ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è —Ü–µ–ª–∏ –Ω–∞ –≤—Å–µ—Ö –¢–§")
        print("üîÑ –¶–ò–ö–õ–ò–ß–ù–û–°–¢–¨: –ø–æ—Å–ª–µ –ø—Ä–æ—Ö–æ–∂–¥–µ–Ω–∏—è –≤—Å–µ—Ö –¢–§ –æ–±—É—á–µ–Ω–∏–µ –Ω–∞—á–Ω–µ—Ç—Å—è –∑–∞–Ω–æ–≤–æ")
        print("=" * 60)
        
        # –°–∫–∞–Ω–∏—Ä—É–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        available_data = self.data_loader.scan_available_data()
        if not available_data:
            print("‚ùå –ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")
            return
        
        print(f"üìä –ù–∞–π–¥–µ–Ω–æ –¥–∞–Ω–Ω—ã—Ö: {len(available_data)} –∫–æ–º–±–∏–Ω–∞—Ü–∏–π")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ
        self._load_learning_state()
        
        self.is_learning = True
        self.learning_start_time = time.time()
        
        # –ë–ï–°–ö–û–ù–ï–ß–ù–´–ô —Ü–∏–∫–ª –ø—Ä–æ–≥—Ä–µ—Å—Å–∏–≤–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è
        iteration = 0
        while True:  # –ë–µ—Å–∫–æ–Ω–µ—á–Ω—ã–π —Ü–∏–∫–ª
            iteration += 1
            print(f"\nüîÑ –ò–¢–ï–†–ê–¶–ò–Ø {iteration} –ë–ï–°–ö–û–ù–ï–ß–ù–û–ì–û –û–ë–£–ß–ï–ù–ò–Ø")
            print("=" * 60)
            
            # –ü—Ä–æ—Ö–æ–¥–∏–º –≤—Å–µ —Ç–∞–π–º—Ñ—Ä–µ–π–º—ã
            while self.current_timeframe_index < len(self.timeframe_progression):
                self.current_timeframe = self.timeframe_progression[self.current_timeframe_index]
                
                print(f"\nüéØ –û–ë–£–ß–ï–ù–ò–ï –ù–ê –¢–ê–ô–ú–§–†–ï–ô–ú–ï: {self.current_timeframe}")
                print(f"üìä –ü—Ä–æ–≥—Ä–µ—Å—Å: {self.current_timeframe_index + 1}/{len(self.timeframe_progression)}")
                print(f"üîÑ –ò—Ç–µ—Ä–∞—Ü–∏—è: {iteration}")
                
                # –û–±—É—á–∞–µ–º—Å—è –Ω–∞ —Ç–µ–∫—É—â–µ–º —Ç–∞–π–º—Ñ—Ä–µ–π–º–µ (–±–µ—Å–∫–æ–Ω–µ—á–Ω–æ –¥–æ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è —Ü–µ–ª–∏)
                success = self._learn_on_timeframe()
                
                if success:
                    print(f"‚úÖ –î–û–°–¢–ò–ì–ù–£–¢ –í–ò–ù–†–ï–ô–¢ 55%+ –ù–ê {self.current_timeframe}")
                    print(f"üéâ –ü–µ—Ä–µ—Ö–æ–¥ –∫ —Å–ª–µ–¥—É—é—â–µ–º—É —Ç–∞–π–º—Ñ—Ä–µ–π–º—É")
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —É—Å–ø–µ—à–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                    self._save_timeframe_success()
                    
                    # –ü–µ—Ä–µ—Ö–æ–¥–∏–º –∫ —Å–ª–µ–¥—É—é—â–µ–º—É —Ç–∞–π–º—Ñ—Ä–µ–π–º—É
                    self.current_timeframe_index += 1
                    self.current_restart = 0
                    
                    if self.current_timeframe_index < len(self.timeframe_progression):
                        print(f"‚è≠Ô∏è –°–ª–µ–¥—É—é—â–∏–π —Ç–∞–π–º—Ñ—Ä–µ–π–º: {self.timeframe_progression[self.current_timeframe_index]}")
                    else:
                        print("üèÜ –í–°–ï –¢–ê–ô–ú–§–†–ï–ô–ú–´ –ü–†–û–ô–î–ï–ù–´ –í –≠–¢–û–ô –ò–¢–ï–†–ê–¶–ò–ò!")
                        break
                else:
                    # –í –Ω–æ–≤–æ–π –ª–æ–≥–∏–∫–µ —ç—Ç–æ –Ω–µ –¥–æ–ª–∂–Ω–æ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç—å, –Ω–æ –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π
                    print(f"‚ùå –ù–ï–û–ñ–ò–î–ê–ù–ù–û: –æ–±—É—á–µ–Ω–∏–µ –ø—Ä–µ—Ä–≤–∞–Ω–æ –Ω–∞ {self.current_timeframe}")
                    self.current_restart += 1
                    
                    if self.current_restart >= self.learning_config['max_restarts']:
                        print(f"‚ö†Ô∏è –î–æ—Å—Ç–∏–≥–Ω—É—Ç –ª–∏–º–∏—Ç –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–æ–≤ –¥–ª—è {self.current_timeframe}")
                        print(f"üîÑ –ü–µ—Ä–µ–∑–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è —Å –Ω–∞—á–∞–ª–∞")
                        self._restart_learning()
                    else:
                        print(f"üîÑ –ü–µ—Ä–µ–∑–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è –Ω–∞ {self.current_timeframe}")
                        self._restart_current_timeframe()
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ
                self._save_learning_state()
            
            # –ü–æ—Å–ª–µ –ø—Ä–æ—Ö–æ–∂–¥–µ–Ω–∏—è –≤—Å–µ—Ö —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤ - –Ω–∞—á–∏–Ω–∞–µ–º –∑–∞–Ω–æ–≤–æ
            print(f"\nüéâ –ò–¢–ï–†–ê–¶–ò–Ø {iteration} –ó–ê–í–ï–†–®–ï–ù–ê!")
            print("üîÑ –ù–ê–ß–ò–ù–ê–ï–ú –ù–û–í–£–Æ –ò–¢–ï–†–ê–¶–ò–Æ –û–ë–£–ß–ï–ù–ò–Ø...")
            
            # –°–±—Ä–∞—Å—ã–≤–∞–µ–º –∏–Ω–¥–µ–∫—Å —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞ –¥–ª—è –Ω–æ–≤–æ–π –∏—Ç–µ—Ä–∞—Ü–∏–∏
            self.current_timeframe_index = 0
            self.current_restart = 0
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∏–Ω–∞–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –∏—Ç–µ—Ä–∞—Ü–∏–∏
            self._save_learning_state()
            
            # –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞ –º–µ–∂–¥—É –∏—Ç–µ—Ä–∞—Ü–∏—è–º–∏
            print("‚è≥ –ü–∞—É–∑–∞ 5 —Å–µ–∫—É–Ω–¥ –ø–µ—Ä–µ–¥ –Ω–æ–≤–æ–π –∏—Ç–µ—Ä–∞—Ü–∏–µ–π...")
            time.sleep(5)
    
    def _learn_on_timeframe(self) -> bool:
        """–û–±—É—á–µ–Ω–∏–µ –Ω–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–º —Ç–∞–π–º—Ñ—Ä–µ–π–º–µ –¥–æ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è 65%+ –≤–∏–Ω—Ä–µ–π—Ç–∞ –∏ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ - –ë–ï–°–ö–û–ù–ï–ß–ù–û–ï –û–ë–£–ß–ï–ù–ò–ï"""
        timeframe_results = []
        cycles_without_improvement = 0
        best_win_rate = 0.0
        cycle = 0
        
        print(f"üîÑ –ë–ï–°–ö–û–ù–ï–ß–ù–û–ï –û–ë–£–ß–ï–ù–ò–ï –ù–ê {self.current_timeframe} –î–û –î–û–°–¢–ò–ñ–ï–ù–ò–Ø 55%+ –í–ò–ù–†–ï–ô–¢–ê")
        
        while True:  # –ë–µ—Å–∫–æ–Ω–µ—á–Ω—ã–π —Ü–∏–∫–ª –æ–±—É—á–µ–Ω–∏—è
            cycle += 1
            self.current_cycle += 1
            print(f"\nüîÑ –¶–∏–∫–ª {cycle} (–±–µ—Å–∫–æ–Ω–µ—á–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ) –Ω–∞ {self.current_timeframe}")
            cycle_result = self._execute_timeframe_cycle()
            timeframe_results.append(cycle_result)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –∫–∞–∂–¥—ã–µ 5 —Ü–∏–∫–ª–æ–≤
            if cycle % self.learning_config['evaluation_cycles'] == 0:
                avg_win_rate = self._calculate_average_win_rate(timeframe_results[-self.learning_config['evaluation_cycles']:])
                print(f"üìä –°—Ä–µ–¥–Ω–∏–π –≤–∏–Ω—Ä–µ–π—Ç –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ {self.learning_config['evaluation_cycles']} —Ü–∏–∫–ª–æ–≤: {avg_win_rate:.1%}")
                print(f"üìà –õ—É—á—à–∏–π –≤–∏–Ω—Ä–µ–π—Ç –Ω–∞ {self.current_timeframe}: {best_win_rate:.1%}")
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç–∏–∂–µ–Ω–∏–µ —Ü–µ–ª–∏ –ø–æ –≤–∏–Ω—Ä–µ–π—Ç—É
                if avg_win_rate >= self.learning_config['target_win_rate']:
                    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: –Ω–µ—Ç –ª–∏ –ø–µ—Ä–µ–∫–æ—Å–∞ –ø–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—é –ø—Ä–∏–±—ã–ª–∏
                    last_cycles = timeframe_results[-self.learning_config['evaluation_cycles']:]
                    all_profits = [trade['profit'] for cycle in last_cycles for trade in cycle['trades'] if 'profit' in trade]
                    if len(all_profits) > 2:
                        sorted_profits = sorted(all_profits, reverse=True)
                        top_2_sum = sum(sorted_profits[:2])
                        total_profit = sum(all_profits)
                        if total_profit > 0 and top_2_sum / total_profit > 0.9:
                            print("‚ö†Ô∏è 90% –ø—Ä–∏–±—ã–ª–∏ –¥–∞—é—Ç 1-2 —Å–¥–µ–ª–∫–∏ ‚Äî –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏!")
                            # –ù–µ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º False, –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ
                        else:
                            print(f"üéØ –î–û–°–¢–ò–ì–ù–£–¢ –¶–ï–õ–ï–í–û–ô –í–ò–ù–†–ï–ô–¢ {avg_win_rate:.1%} >= 55%! –ü–µ—Ä–µ—Ö–æ–¥ –∫ —Å–ª–µ–¥—É—é—â–µ–º—É —Ç–∞–π–º—Ñ—Ä–µ–π–º—É.")
                            return True
                    else:
                        print(f"üéØ –î–û–°–¢–ò–ì–ù–£–¢ –¶–ï–õ–ï–í–û–ô –í–ò–ù–†–ï–ô–¢ {avg_win_rate:.1%} >= 55%! –ü–µ—Ä–µ—Ö–æ–¥ –∫ —Å–ª–µ–¥—É—é—â–µ–º—É —Ç–∞–π–º—Ñ—Ä–µ–π–º—É.")
                        return True
                
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø—Ä–æ—Å–∞–¥–∫—É: –µ—Å–ª–∏ –±–∞–ª–∞–Ω—Å –≤—ã—Ä–æ—Å, –Ω–æ –≤–∏–Ω—Ä–µ–π—Ç –Ω–∏–∑–∫–∏–π ‚Äî –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ
                last_cycle = timeframe_results[-1]
                if last_cycle['end_capital'] > last_cycle['start_capital'] and avg_win_rate < self.learning_config['target_win_rate']:
                    print("‚ö†Ô∏è –ë–∞–ª–∞–Ω—Å –≤—ã—Ä–æ—Å, –Ω–æ –≤–∏–Ω—Ä–µ–π—Ç –Ω–∏–∑–∫–∏–π ‚Äî –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –≤–∏–Ω—Ä–µ–π—Ç–∞!")
                    # –ù–µ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º False, –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É–ª—É—á—à–µ–Ω–∏–µ
                if avg_win_rate > best_win_rate:
                    best_win_rate = avg_win_rate
                    cycles_without_improvement = 0
                    print(f"üéâ –ù–û–í–´–ô –†–ï–ö–û–†–î –í–ò–ù–†–ï–ô–¢–ê: {best_win_rate:.1%}!")
                else:
                    cycles_without_improvement += 1
                
                # –ï—Å–ª–∏ –Ω–µ—Ç —É–ª—É—á—à–µ–Ω–∏–π –æ—á–µ–Ω—å –¥–æ–ª–≥–æ, –ø–æ–∫–∞–∑—ã–≤–∞–µ–º —ç—Ç–æ, –Ω–æ –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ
                if cycles_without_improvement >= self.learning_config['max_cycles_without_improvement']:
                    print(f"‚ö†Ô∏è –ù–µ—Ç —É–ª—É—á—à–µ–Ω–∏–π {cycles_without_improvement} —Ü–∏–∫–ª–æ–≤, –Ω–æ –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ...")
                    cycles_without_improvement = 0  # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å—á–µ—Ç—á–∏–∫, –Ω–æ –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ –∫–∞–∂–¥—ã–µ 50 —Ü–∏–∫–ª–æ–≤
                if cycle % 50 == 0:
                    self._save_learning_state()
                    print(f"üíæ –°–æ—Å—Ç–æ—è–Ω–∏–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ –ø–æ—Å–ª–µ {cycle} —Ü–∏–∫–ª–æ–≤ –æ–±—É—á–µ–Ω–∏—è")
    
    def _execute_timeframe_cycle(self) -> Dict:
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –æ–¥–Ω–æ–≥–æ —Ü–∏–∫–ª–∞ –æ–±—É—á–µ–Ω–∏—è –Ω–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–º —Ç–∞–π–º—Ñ—Ä–µ–π–º–µ"""
        
        # üß† –£–õ–£–ß–®–ï–ù–ù–ê–Ø –í–ï–†–°–ò–Ø: –ù–ï –°–ë–†–ê–°–´–í–ê–ï–ú –ö–ê–ü–ò–¢–ê–õ –ö–ê–ñ–î–´–ô –¶–ò–ö–õ
        # –°–±—Ä–æ—Å —Ç–æ–ª—å–∫–æ –ø—Ä–∏ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏–∏ —Ü–µ–ª–∏ –∏–ª–∏ –∫–∞–∂–¥—ã–µ 100 —Ü–∏–∫–ª–æ–≤
        if self.current_cycle % 100 == 0:
            self.neural_network.current_capital = 100.0
            print(f"   üí∞ –°–±—Ä–æ—Å –∫–∞–ø–∏—Ç–∞–ª–∞ –¥–æ $100 (–∫–∞–∂–¥—ã–µ 100 —Ü–∏–∫–ª–æ–≤)")
        else:
            print(f"   üí∞ –¢–µ–∫—É—â–∏–π –∫–∞–ø–∏—Ç–∞–ª: ${self.neural_network.current_capital:.2f}")
        
        cycle_results = {
            'cycle': self.current_cycle,
            'timeframe': self.current_timeframe,
            'trades': [],
            'total_profit': 0.0,
            'win_count': 0,
            'loss_count': 0,
            'start_capital': self.neural_network.current_capital
        }
        
        # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤
        symbols = self.data_loader.get_all_symbols()
        
        print(f"   üìä –ö–∞–ø–∏—Ç–∞–ª –≤ –Ω–∞—á–∞–ª–µ —Ü–∏–∫–ª–∞: ${self.neural_network.current_capital:.2f}")
        print(f"   üéØ –°–¥–µ–ª–∫–∏ –Ω–∞ {self.current_timeframe}:")
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º —Å–¥–µ–ª–∫–∏ —Ç–æ–ª—å–∫–æ –Ω–∞ —Ç–µ–∫—É—â–µ–º —Ç–∞–π–º—Ñ—Ä–µ–π–º–µ
        for trade_num in range(self.learning_config['trades_per_cycle']):
            symbol = random.choice(symbols)
            
            try:
                # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ —Ç–æ–ª—å–∫–æ –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞
                market_data = self.data_loader.get_market_data_sample(symbol, self.current_timeframe)
                
                if not market_data:
                    continue
                
                # –ù–µ–π—Ä–æ—Å–µ—Ç—å –ø—Ä–∏–Ω–∏–º–∞–µ—Ç —Ä–µ—à–µ–Ω–∏–µ
                decision = self.neural_network.make_autonomous_decision(market_data)
                
                # –°–∏–º—É–ª–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å–¥–µ–ª–∫–∏
                trade_result = self._simulate_trade(market_data, decision)
                
                # –ù–µ–π—Ä–æ—Å–µ—Ç—å —É—á–∏—Ç—Å—è –Ω–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ
                self.neural_network.learn_from_result(decision, trade_result)
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                trade_info = {
                    'symbol': symbol,
                    'timeframe': self.current_timeframe,
                    'decision': decision,
                    'result': trade_result
                }
                cycle_results['trades'].append(trade_info)
                cycle_results['total_profit'] += trade_result['profit']
                
                if trade_result['profit'] > 0:
                    cycle_results['win_count'] += 1
                else:
                    cycle_results['loss_count'] += 1
                
                # –ù–æ–≤—ã–π –≤—ã–≤–æ–¥: –ø–æ–∫–∞–∑—ã–≤–∞–µ–º, –±—ã–ª –ª–∏ exploration
                if decision.get('exploration', False):
                    print(f"      ‚ö°Ô∏è [EXPLORATION] –†–µ—à–µ–Ω–∏–µ –ø—Ä–∏–Ω—è—Ç–æ —Å–ª—É—á–∞–π–Ω–æ!")
                
            except Exception as e:
                print(f"   ‚ùå –û—à–∏–±–∫–∞ –≤ —Å–¥–µ–ª–∫–µ {trade_num}: {e}")
                continue
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        cycle_results['end_capital'] = self.neural_network.current_capital
        cycle_results['win_rate'] = cycle_results['win_count'] / self.learning_config['trades_per_cycle'] if self.learning_config['trades_per_cycle'] > 0 else 0.0
        
        print(f"   üìà –ö–∞–ø–∏—Ç–∞–ª –≤ –∫–æ–Ω—Ü–µ —Ü–∏–∫–ª–∞: ${self.neural_network.current_capital:.2f}")
        print(f"   üí∞ –û–±—â–∞—è –ø—Ä–∏–±—ã–ª—å —Ü–∏–∫–ª–∞: ${cycle_results['total_profit']:.2f}")
        print(f"   üéØ –í–∏–Ω—Ä–µ–π—Ç —Ü–∏–∫–ª–∞: {cycle_results['win_rate']:.1%} ({cycle_results['win_count']}/{self.learning_config['trades_per_cycle']})")
        
        return cycle_results
    
    def _calculate_average_win_rate(self, results: List[Dict]) -> float:
        """–í—ã—á–∏—Å–ª—è–µ—Ç —Å—Ä–µ–¥–Ω–∏–π –≤–∏–Ω—Ä–µ–π—Ç –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Ü–∏–∫–ª—ã"""
        if not results:
            return 0.0
        
        total_win_rate = sum(r['win_rate'] for r in results)
        return total_win_rate / len(results)
    
    def _simulate_trade(self, market_data: Dict, decision: Dict) -> Dict:
        """–°–∏–º—É–ª—è—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ —Å–¥–µ–ª–∫–∏ —Å –ø–ª–∞–≤–∞—é—â–∏–º —Ä–∞–∑–º–µ—Ä–æ–º –ø–æ–∑–∏—Ü–∏–∏, –ø–ª–µ—á–æ–º, –∫–æ–º–∏—Å—Å–∏—è–º–∏ –∏ —Ä–∏—Å–∫-–º–µ–Ω–µ–¥–∂–º–µ–Ω—Ç–æ–º 1:2 (R = —Ä–∏—Å–∫ –Ω–∞ —Å–¥–µ–ª–∫—É)"""
        import math
        entry_price = float(market_data.get('close', 0))
        if entry_price <= 0:
            entry_price = 1.0
        action = decision.get('action', 'buy')
        if action not in ['buy', 'sell']:
            action = 'buy'
        # –†–∞–∑–º–µ—Ä –ø–æ–∑–∏—Ü–∏–∏: % –æ—Ç –∫–∞–ø–∏—Ç–∞–ª–∞
        position_size = max(0.01, min(1.0, float(decision.get('position_size', 0.05))))
        leverage = max(1, min(20, int(decision.get('leverage', 1))))
        capital = max(1.0, float(self.neural_network.current_capital))
        # –†–∏—Å–∫ –Ω–∞ —Å–¥–µ–ª–∫—É (R): 1% –æ—Ç –∫–∞–ø–∏—Ç–∞–ª–∞
        risk_percent = 0.01
        risk_per_trade = capital * risk_percent
        # –°—Ç–æ–∏–º–æ—Å—Ç—å –ø–æ–∑–∏—Ü–∏–∏ (–º–∞—Ä–∂–∞)
        margin = capital * position_size
        notional = margin * leverage
        # –ü—Ä–æ–≤–µ—Ä–∫–∞: –Ω–µ –æ—Ç–∫—Ä—ã–≤–∞—Ç—å —Å–¥–µ–ª–∫—É, –µ—Å–ª–∏ –º–∞—Ä–∂–∞ > –∫–∞–ø–∏—Ç–∞–ª (–¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏)
        if margin > capital:
            print(f"   ‚ö†Ô∏è –°–¥–µ–ª–∫–∞ –ø—Ä–æ–ø—É—â–µ–Ω–∞: margin (${margin:.2f}) > –∫–∞–ø–∏—Ç–∞–ª (${capital:.2f})")
            return {'profit': 0.0, 'fees': 0.0, 'exit_reason': 'skipped', 'action': action, 'position_size': position_size, 'leverage': leverage}
        # –ö–æ–ª-–≤–æ –º–æ–Ω–µ—Ç
        coins = notional / entry_price
        # –ö–æ–º–∏—Å—Å–∏–∏ (Binance Futures): 0.02% –≤—Ö–æ–¥, 0.04% –≤—ã—Ö–æ–¥ –æ—Ç notional
        entry_fee = notional * self.entry_fee
        exit_fee = notional * self.exit_fee
        total_fees = entry_fee + exit_fee
        # –°–∏–º—É–ª–∏—Ä—É–µ–º –¥–≤–∏–∂–µ–Ω–∏–µ —Ü–µ–Ω—ã (–≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å)
        timeframe_multiplier = self._get_timeframe_volatility()
        max_move = 0.10 * timeframe_multiplier
        price_move = random.uniform(-max_move, max_move)
        if action == 'buy':
            exit_price = entry_price * (1 + price_move)
        else:
            exit_price = entry_price * (1 - price_move)
        exit_price = max(0.0001, exit_price)
        # –ü—Ä–∏–±—ã–ª—å/—É–±—ã—Ç–æ–∫ –¥–æ –∫–æ–º–∏—Å—Å–∏–π
        if action == 'buy':
            pnl = (exit_price - entry_price) * coins
        else:
            pnl = (entry_price - exit_price) * coins
        # --- –†–∏—Å–∫-–º–µ–Ω–µ–¥–∂–º–µ–Ω—Ç 1:2 ---
        # –°—Ç–æ–ø-–ª–æ—Å—Å: -R (—É–±—ã—Ç–æ–∫ = -risk_per_trade)
        # –¢–µ–π–∫-–ø—Ä–æ—Ñ–∏—Ç: +2R (–ø—Ä–∏–±—ã–ª—å = +2*risk_per_trade)
        exit_reason = 'market_exit'
        gross_pnl = pnl
        if pnl < -risk_per_trade:
            gross_pnl = -risk_per_trade
            exit_reason = 'stop_loss'
        elif pnl > 2 * risk_per_trade:
            gross_pnl = 2 * risk_per_trade
            exit_reason = 'take_profit'
        # –ß–∏—Å—Ç–∞—è –ø—Ä–∏–±—ã–ª—å —Å —É—á–µ—Ç–æ–º –∫–æ–º–∏—Å—Å–∏–π
        net_profit = gross_pnl - total_fees
        # –õ–æ–≥–∏—Ä–æ–≤–∞—Ç—å, –µ—Å–ª–∏ –∫–æ–º–∏—Å—Å–∏—è –ø—Ä–µ–≤—ã—à–∞–µ—Ç –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—É—é –ø—Ä–∏–±—ã–ª—å (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ gross_pnl > 0)
        if gross_pnl > 0 and abs(total_fees) > abs(gross_pnl):
            print(f"   ‚ö†Ô∏è –ö–æ–º–∏—Å—Å–∏—è (${total_fees:.2f}) –ø—Ä–µ–≤—ã—à–∞–µ—Ç –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—É—é –ø—Ä–∏–±—ã–ª—å (${gross_pnl:.2f})!")
        # –ó–∞—â–∏—Ç–∞ –æ—Ç –ø–µ—Ä–µ–ø–æ–ª–Ω–µ–Ω–∏—è
        if not math.isfinite(net_profit):
            net_profit = 0.0
        if not math.isfinite(total_fees):
            total_fees = 0.0
        # –û–±–Ω–æ–≤–ª—è–µ–º –∫–∞–ø–∏—Ç–∞–ª
        self.neural_network.current_capital += net_profit
        print(f"   üí∞ {market_data.get('symbol', 'UNKNOWN')} {action.upper()}: –¶–µ–Ω–∞ ${entry_price:.4f}‚Üí${exit_price:.4f}, –†–∞–∑–º–µ—Ä {position_size:.1%}, –ü–ª–µ—á–æ {leverage}x, –ü—Ä–∏–±—ã–ª—å ${net_profit:.2f} (–∫–æ–º–∏—Å—Å–∏–∏: ${total_fees:.2f}) ({exit_reason})")
        return {
            'entry_price': entry_price,
            'exit_price': exit_price,
            'profit': net_profit,
            'fees': total_fees,
            'exit_reason': exit_reason,
            'action': action,
            'position_size': position_size,
            'leverage': leverage,
            'market_data': market_data  # üß† –î–æ–±–∞–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ —Ä—ã–Ω–∫–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
        }
    
    def _get_timeframe_volatility(self) -> float:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –º–Ω–æ–∂–∏—Ç–µ–ª—å –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏ –¥–ª—è —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞"""
        volatility_map = {
            '1M': 2.0, '1w': 1.5, '1d': 1.2, '12h': 1.1, '8h': 1.0,
            '6h': 0.9, '4h': 0.8, '2h': 0.7, '1h': 0.6, '30m': 0.5,
            '15m': 0.4, '5m': 0.3, '3m': 0.25, '1m': 0.2
        }
        return volatility_map.get(self.current_timeframe, 1.0)
    
    def _restart_learning(self):
        """–ü–æ–ª–Ω—ã–π –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è"""
        print("üîÑ –ü–û–õ–ù–´–ô –ü–ï–†–ï–ó–ê–ü–£–°–ö –û–ë–£–ß–ï–ù–ò–Ø")
        print("üí∞ –°–±—Ä–æ—Å –∫–∞–ø–∏—Ç–∞–ª–∞ –¥–æ $100")
        self.neural_network = AutonomousNeuralNetwork(100.0)  # –í—Å–µ–≥–¥–∞ –Ω–∞—á–∏–Ω–∞–µ–º —Å $100
        self.neural_network.current_capital = 100.0  # –ì–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º —Å–±—Ä–æ—Å
        self.current_timeframe_index = 0
        self.current_restart = 0
        self.current_cycle = 0
        self.learning_history = []
        self.timeframe_history = []
    
    def _restart_current_timeframe(self):
        """–ü–µ—Ä–µ–∑–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è –Ω–∞ —Ç–µ–∫—É—â–µ–º —Ç–∞–π–º—Ñ—Ä–µ–π–º–µ"""
        print(f"üîÑ –ü–ï–†–ï–ó–ê–ü–£–°–ö –ù–ê –¢–ê–ô–ú–§–†–ï–ô–ú–ï {self.current_timeframe}")
        print("üí∞ –°–±—Ä–æ—Å –∫–∞–ø–∏—Ç–∞–ª–∞ –¥–æ $100")
        self.neural_network.current_capital = 100.0  # –ì–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º —Å–±—Ä–æ—Å
        self.current_cycle = 0
    
    def _save_timeframe_success(self):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —É—Å–ø–µ—à–Ω–æ–µ –ø—Ä–æ—Ö–æ–∂–¥–µ–Ω–∏–µ —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞"""
        success_record = {
            'timeframe': self.current_timeframe,
            'cycle': self.current_cycle,
            'timestamp': datetime.now().isoformat(),
            'capital': self.neural_network.current_capital
        }
        self.timeframe_history.append(success_record)
    
    def _save_learning_state(self):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å–æ—Å—Ç–æ—è–Ω–∏–µ –æ–±—É—á–µ–Ω–∏—è"""
        state = {
            'current_timeframe_index': self.current_timeframe_index,
            'current_timeframe': self.current_timeframe,
            'current_cycle': self.current_cycle,
            'current_restart': self.current_restart,
            'neural_network_state': self.neural_network.get_state(),
            'timeframe_history': self.timeframe_history,
            'learning_history': self.learning_history[-100:]  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 100 –∑–∞–ø–∏—Å–µ–π
        }
        
        with open('progressive_learning_state.json', 'w', encoding='utf-8') as f:
            json.dump(state, f, indent=2, ensure_ascii=False)
    
    def _load_learning_state(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å–æ—Å—Ç–æ—è–Ω–∏–µ –æ–±—É—á–µ–Ω–∏—è"""
        try:
            if os.path.exists('progressive_learning_state.json'):
                with open('progressive_learning_state.json', 'r', encoding='utf-8') as f:
                    state = json.load(f)
                
                self.current_timeframe_index = state.get('current_timeframe_index', 0)
                self.current_timeframe = state.get('current_timeframe', self.timeframe_progression[0])
                self.current_cycle = state.get('current_cycle', 0)
                self.current_restart = state.get('current_restart', 0)
                self.timeframe_history = state.get('timeframe_history', [])
                self.learning_history = state.get('learning_history', [])
                
                # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏
                neural_state = state.get('neural_network_state', {})
                if neural_state:
                    self.neural_network.load_state(neural_state)
                
                print(f"üìÇ –ó–∞–≥—Ä—É–∂–µ–Ω–æ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –æ–±—É—á–µ–Ω–∏—è —Å —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞ {self.current_timeframe}")
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Å–æ—Å—Ç–æ—è–Ω–∏—è: {e}")
    
    def _final_evaluation(self):
        """–§–∏–Ω–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –æ–±—É—á–µ–Ω–∏—è"""
        print("\nüèÜ –§–ò–ù–ê–õ–¨–ù–ê–Ø –û–¶–ï–ù–ö–ê –ü–†–û–ì–†–ï–°–°–ò–í–ù–û–ì–û –û–ë–£–ß–ï–ù–ò–Ø")
        print("=" * 60)
        
        if self.timeframe_history:
            print("‚úÖ –£–°–ü–ï–®–ù–û –ü–†–û–ô–î–ï–ù–ù–´–ï –¢–ê–ô–ú–§–†–ï–ô–ú–´:")
            for record in self.timeframe_history:
                print(f"   üìä {record['timeframe']}: —Ü–∏–∫–ª {record['cycle']}, –∫–∞–ø–∏—Ç–∞–ª ${record['capital']:.2f}")
        
        final_capital = float(self.neural_network.current_capital or 100.0)
        print(f"üí∞ –§–∏–Ω–∞–ª—å–Ω—ã–π –∫–∞–ø–∏—Ç–∞–ª: ${final_capital:.2f}")
        print(f"üìà –û–±—â–∞—è –ø—Ä–∏–±—ã–ª—å: ${final_capital - 100.0:.2f}")
        
        learning_time = 0.0
        if self.learning_start_time is not None:
            learning_time = (time.time() - self.learning_start_time) / 60
        print(f"‚è±Ô∏è –í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è: {learning_time:.1f} –º–∏–Ω—É—Ç")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∏–Ω–∞–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ
        with open('final_progressive_learning_state.json', 'w', encoding='utf-8') as f:
            json.dump({
                'timeframe_history': self.timeframe_history,
                'final_capital': final_capital,
                'total_profit': final_capital - 100.0,
                'learning_time_minutes': learning_time
            }, f, indent=2, ensure_ascii=False)
        
        print("üíæ –§–∏–Ω–∞–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ final_progressive_learning_state.json")
    
    def get_learning_summary(self) -> Dict:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–≤–æ–¥–∫—É –æ–±—É—á–µ–Ω–∏—è"""
        current_capital = float(self.neural_network.current_capital or 100.0)
        return {
            'current_timeframe': self.current_timeframe,
            'current_timeframe_index': self.current_timeframe_index,
            'current_cycle': self.current_cycle,
            'current_restart': self.current_restart,
            'current_capital': current_capital,
            'current_profit': current_capital - 100.0,
            'timeframe_history': self.timeframe_history,
            'best_performance': self.best_performance
        } 