"""
üß† –ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π —ç–≤–æ–ª—é—Ü–∏–æ–Ω–Ω–æ–≥–æ –∞–≥–µ–Ω—Ç–∞
–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –º–∏–ª–ª–∏–æ–Ω—ã –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∏ –Ω–∞—Ö–æ–¥–∏—Ç –ø–∞—Ç—Ç–µ—Ä–Ω—ã —É—Å–ø–µ—Ö–∞/–æ—à–∏–±–æ–∫
–°–∏—Å—Ç–µ–º–∞ —É–º–Ω–æ–≥–æ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∑–Ω–∞–Ω–∏—è–º–∏ —Å —Ä–æ—Ç–∞—Ü–∏–µ–π –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π
"""

import json
import os
import pandas as pd
from typing import Dict, List, Any, Optional
from datetime import datetime, timedelta
import numpy as np
from collections import defaultdict, Counter
import shutil

class KnowledgeAnalyzer:
    """
    –ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π –¥–ª—è –ø–æ–∏—Å–∫–∞ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –≤ –º–∏–ª–ª–∏–æ–Ω–∞—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
    """
    
    def __init__(self, data_dir: str = "learning_data"):
        self.data_dir = data_dir
        self.knowledge_base = {}
        self.individuals_data = []
        self.trades_df = None
        self.errors_df = None
        
    def load_knowledge_base(self, filename: Optional[str] = None):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –±–∞–∑—É –∑–Ω–∞–Ω–∏–π –∏–∑ —Ñ–∞–π–ª–∞"""
        if filename is None:
            # –ò—â–µ–º —Å–∞–º—ã–π —Å–≤–µ–∂–∏–π —Ñ–∞–π–ª –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π
            files = [f for f in os.listdir(self.data_dir) if f.startswith("knowledge_base_")]
            if not files:
                raise FileNotFoundError("–§–∞–π–ª—ã –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
            filename = max(files)  # –°–∞–º—ã–π —Å–≤–µ–∂–∏–π —Ñ–∞–π–ª
        
        filepath = os.path.join(self.data_dir, filename)
        with open(filepath, 'r', encoding='utf-8') as f:
            self.knowledge_base = json.load(f)
        
        print(f"‚úÖ –ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π –∑–∞–≥—Ä—É–∂–µ–Ω–∞: {filename}")
        return self.knowledge_base
    
    def load_individuals_data(self, timestamp: Optional[str] = None):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –≤—Å–µ—Ö –∏–Ω–¥–∏–≤–∏–¥–æ–≤"""
        files = [f for f in os.listdir(self.data_dir) if f.startswith("individual_")]
        
        if timestamp:
            files = [f for f in files if timestamp in f]
        
        self.individuals_data = []
        for filename in files:
            filepath = os.path.join(self.data_dir, filename)
            try:
                with open(filepath, 'r', encoding='utf-8') as f:
                    individual_data = json.load(f)
                    self.individuals_data.append(individual_data)
            except Exception as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {filename}: {e}")
        
        print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(self.individuals_data)} –∏–Ω–¥–∏–≤–∏–¥–æ–≤")
        return self.individuals_data
    
    def create_trades_dataframe(self):
        """–°–æ–∑–¥–∞–µ—Ç DataFrame —Å–æ –≤—Å–µ–º–∏ —Å–¥–µ–ª–∫–∞–º–∏"""
        all_trades = []
        
        for individual in self.individuals_data:
            individual_id = individual['individual_id']
            for trade in individual['trade_history']:
                trade['individual_id'] = individual_id
                all_trades.append(trade)
        
        if all_trades:
            self.trades_df = pd.DataFrame(all_trades)
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º timestamp –≤ datetime
            self.trades_df['timestamp'] = pd.to_datetime(self.trades_df['timestamp'])
            print(f"‚úÖ –°–æ–∑–¥–∞–Ω DataFrame —Å {len(self.trades_df)} —Å–¥–µ–ª–∫–∞–º–∏")
        else:
            self.trades_df = pd.DataFrame()
            print("‚ö†Ô∏è –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ —Å–¥–µ–ª–∫–∞—Ö")
        
        return self.trades_df
    
    def create_errors_dataframe(self):
        """–°–æ–∑–¥–∞–µ—Ç DataFrame —Å–æ –≤—Å–µ–º–∏ –æ—à–∏–±–∫–∞–º–∏"""
        all_errors = []
        
        for individual in self.individuals_data:
            individual_id = individual['individual_id']
            for error in individual['error_history']:
                error['individual_id'] = individual_id
                all_errors.append(error)
        
        if all_errors:
            self.errors_df = pd.DataFrame(all_errors)
            self.errors_df['timestamp'] = pd.to_datetime(self.errors_df['timestamp'])
            print(f"‚úÖ –°–æ–∑–¥–∞–Ω DataFrame —Å {len(self.errors_df)} –æ—à–∏–±–∫–∞–º–∏")
        else:
            self.errors_df = pd.DataFrame()
            print("‚ö†Ô∏è –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ–± –æ—à–∏–±–∫–∞—Ö")
        
        return self.errors_df
    
    def analyze_successful_patterns(self) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —É—Å–ø–µ—à–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã"""
        if self.trades_df is None or self.trades_df.empty:
            return {}
        
        # –ê–Ω–∞–ª–∏–∑ –ø–æ —Å–∏–º–≤–æ–ª–∞–º
        symbol_analysis = self.trades_df.groupby('symbol').agg({
            'win': ['count', 'mean'],
            'pnl': ['mean', 'std'],
            'pnl_pct': ['mean', 'std']
        }).round(4)
        
        # –ê–Ω–∞–ª–∏–∑ –ø–æ —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞–º
        timeframe_analysis = self.trades_df.groupby('timeframe').agg({
            'win': ['count', 'mean'],
            'pnl': ['mean', 'std']
        }).round(4)
        
        # –ê–Ω–∞–ª–∏–∑ –ø–æ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è–º
        direction_analysis = self.trades_df.groupby('direction').agg({
            'win': ['count', 'mean'],
            'pnl': ['mean', 'std']
        }).round(4)
        
        # –ê–Ω–∞–ª–∏–∑ –ø–æ –ø–ª–µ—á—É
        leverage_analysis = self.trades_df.groupby('leverage').agg({
            'win': ['count', 'mean'],
            'pnl': ['mean', 'std']
        }).round(4)
        
        # –ù–û–í–´–ô –ê–ù–ê–õ–ò–ó: –°–¢–û–ü-–õ–û–°–°–´ –ò –¢–ï–ô–ö-–ü–†–û–§–ò–¢–´
        stop_loss_analysis = None
        take_profit_analysis = None
        close_reason_analysis = None
        
        if 'stop_loss_pct' in self.trades_df.columns:
            stop_loss_analysis = self.trades_df.groupby('stop_loss_pct').agg({
                'win': ['count', 'mean'],
                'pnl': ['mean', 'std']
            }).round(4)
        
        if 'take_profit_pct' in self.trades_df.columns:
            take_profit_analysis = self.trades_df.groupby('take_profit_pct').agg({
                'win': ['count', 'mean'],
                'pnl': ['mean', 'std']
            }).round(4)
        
        if 'close_reason' in self.trades_df.columns:
            close_reason_analysis = self.trades_df.groupby('close_reason').agg({
                'win': ['count', 'mean'],
                'pnl': ['mean', 'std']
            }).round(4)
        
        # –ê–Ω–∞–ª–∏–∑ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏—è —Ä–∏—Å–∫/–ø—Ä–∏–±—ã–ª—å
        risk_reward_analysis = None
        if 'stop_loss_pct' in self.trades_df.columns and 'take_profit_pct' in self.trades_df.columns:
            self.trades_df['risk_reward_ratio'] = self.trades_df['take_profit_pct'] / self.trades_df['stop_loss_pct']
            risk_reward_analysis = self.trades_df.groupby('risk_reward_ratio').agg({
                'win': ['count', 'mean'],
                'pnl': ['mean', 'std']
            }).round(4)
        
        # –¢–æ–ø-10 —Å–∞–º—ã—Ö –ø—Ä–∏–±—ã–ª—å–Ω—ã—Ö —Å–¥–µ–ª–æ–∫
        top_trades = self.trades_df.nlargest(10, 'pnl')[['symbol', 'direction', 'pnl', 'pnl_pct', 'leverage', 'timestamp']]
        
        # –¢–æ–ø-10 —Å–∞–º—ã—Ö —É–±—ã—Ç–æ—á–Ω—ã—Ö —Å–¥–µ–ª–æ–∫
        worst_trades = self.trades_df.nsmallest(10, 'pnl')[['symbol', 'direction', 'pnl', 'pnl_pct', 'leverage', 'timestamp']]
        
        return {
            'symbol_analysis': symbol_analysis,
            'timeframe_analysis': timeframe_analysis,
            'direction_analysis': direction_analysis,
            'leverage_analysis': leverage_analysis,
            'stop_loss_analysis': stop_loss_analysis,
            'take_profit_analysis': take_profit_analysis,
            'close_reason_analysis': close_reason_analysis,
            'risk_reward_analysis': risk_reward_analysis,
            'top_trades': top_trades,
            'worst_trades': worst_trades,
            'total_trades': len(self.trades_df),
            'winrate': (self.trades_df['win'].sum() / len(self.trades_df) * 100).round(2),
            'avg_pnl': self.trades_df['pnl'].mean().round(4),
            'total_pnl': self.trades_df['pnl'].sum().round(4)
        }
    
    def analyze_error_patterns(self) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø–∞—Ç—Ç–µ—Ä–Ω—ã –æ—à–∏–±–æ–∫"""
        if self.errors_df is None or self.errors_df.empty:
            return {}
        
        # –ê–Ω–∞–ª–∏–∑ –ø–æ —Ç–∏–ø–∞–º –æ—à–∏–±–æ–∫
        error_types = self.errors_df['error_type'].value_counts()
        
        # –ê–Ω–∞–ª–∏–∑ –ø–æ —Å–∏–º–≤–æ–ª–∞–º —Å –æ—à–∏–±–∫–∞–º–∏
        symbol_errors = self.errors_df['symbol'].value_counts()
        
        # –ê–Ω–∞–ª–∏–∑ –ø–æ —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞–º —Å –æ—à–∏–±–∫–∞–º–∏
        timeframe_errors = self.errors_df['timeframe'].value_counts()
        
        # –ß–∞—Å—Ç—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è –æ–± –æ—à–∏–±–∫–∞—Ö
        error_messages = self.errors_df['error_message'].value_counts().head(10)
        
        return {
            'error_types': error_types,
            'symbol_errors': symbol_errors,
            'timeframe_errors': timeframe_errors,
            'error_messages': error_messages,
            'total_errors': len(self.errors_df)
        }
    
    def analyze_parameter_evolution(self) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —ç–≤–æ–ª—é—Ü–∏—é –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤"""
        if not self.individuals_data:
            return {}
        
        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        all_params = []
        for individual in self.individuals_data:
            for trade in individual['trade_history']:
                params = trade.get('params', {})
                params['individual_id'] = individual['individual_id']
                params['win'] = trade['win']
                params['pnl'] = trade['pnl']
                params['timestamp'] = trade['timestamp']
                all_params.append(params)
        
        if not all_params:
            return {}
        
        params_df = pd.DataFrame(all_params)
        params_df['timestamp'] = pd.to_datetime(params_df['timestamp'])
        
        # –ê–Ω–∞–ª–∏–∑ –ø–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º
        leverage_winrate = params_df.groupby('leverage')['win'].agg(['count', 'mean']).round(4)
        position_size_winrate = params_df.groupby('position_size')['win'].agg(['count', 'mean']).round(4)
        budget_frac_winrate = params_df.groupby('budget_frac')['win'].agg(['count', 'mean']).round(4)
        
        # –õ—É—á—à–∏–µ –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        best_combinations = params_df.groupby(['leverage', 'position_size', 'budget_frac']).agg({
            'win': ['count', 'mean'],
            'pnl': ['mean', 'sum']
        }).round(4)
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ winrate
        best_combinations = best_combinations.sort_values(('win', 'mean'), ascending=False)
        
        return {
            'leverage_winrate': leverage_winrate,
            'position_size_winrate': position_size_winrate,
            'budget_frac_winrate': budget_frac_winrate,
            'best_combinations': best_combinations.head(20)
        }
    
    def find_optimal_parameters(self) -> Dict[str, Any]:
        """–ù–∞—Ö–æ–¥–∏—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞"""
        if self.trades_df is None or self.trades_df.empty:
            return {}
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º –∏ –Ω–∞—Ö–æ–¥–∏–º –ª—É—á—à–∏–µ
        params_df = pd.DataFrame([
            {
                'leverage': trade.get('params', {}).get('leverage'),
                'position_size': trade.get('params', {}).get('position_size'),
                'budget_frac': trade.get('params', {}).get('budget_frac'),
                'win': trade['win'],
                'pnl': trade['pnl']
            }
            for trade in self.trades_df.to_dict('records')
            if trade.get('params')
        ])
        
        if params_df.empty:
            return {}
        
        # –ù–∞—Ö–æ–¥–∏–º –ª—É—á—à–∏–µ –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏ (–º–∏–Ω–∏–º—É–º 10 —Å–¥–µ–ª–æ–∫)
        combinations = params_df.groupby(['leverage', 'position_size', 'budget_frac']).agg({
            'win': ['count', 'mean'],
            'pnl': ['mean', 'sum']
        }).round(4)
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É —Å–¥–µ–ª–æ–∫
        combinations = combinations[combinations[('win', 'count')] >= 10]
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ winrate –∏ –ø—Ä–∏–±—ã–ª–∏
        combinations = combinations.sort_values([
            ('win', 'mean'), 
            ('pnl', 'sum')
        ], ascending=[False, False])
        
        best_params = combinations.head(5)
        
        return {
            'best_parameters': best_params,
            'recommendations': self._generate_recommendations(best_params)
        }
    
    def _generate_recommendations(self, best_params) -> List[str]:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ª—É—á—à–∏—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤"""
        recommendations = []
        
        if best_params.empty:
            return ["–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π"]
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ª—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        best_leverage = best_params.index.get_level_values('leverage').mode()[0]
        best_position_size = best_params.index.get_level_values('position_size').mean()
        best_budget_frac = best_params.index.get_level_values('budget_frac').mean()
        
        recommendations.append(f"–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º–æ–µ –ø–ª–µ—á–æ: {best_leverage}x")
        recommendations.append(f"–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–π —Ä–∞–∑–º–µ—Ä –ø–æ–∑–∏—Ü–∏–∏: {best_position_size*100:.1f}%")
        recommendations.append(f"–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º–∞—è –¥–æ–ª—è –±—é–¥–∂–µ—Ç–∞: {best_budget_frac*100:.1f}%")
        
        # –ê–Ω–∞–ª–∏–∑ –ø–æ —Å–∏–º–≤–æ–ª–∞–º
        if self.trades_df is not None and not self.trades_df.empty:
            best_symbols = self.trades_df.groupby('symbol')['win'].mean().nlargest(3)
            recommendations.append(f"–õ—É—á—à–∏–µ —Å–∏–º–≤–æ–ª—ã: {', '.join(best_symbols.index)}")
        
        # –ê–Ω–∞–ª–∏–∑ –ø–æ —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞–º
        if self.trades_df is not None and not self.trades_df.empty:
            best_timeframes = self.trades_df.groupby('timeframe')['win'].mean().nlargest(3)
            recommendations.append(f"–õ—É—á—à–∏–µ —Ç–∞–π–º—Ñ—Ä–µ–π–º—ã: {', '.join(best_timeframes.index)}")
        
        return recommendations
    
    def generate_full_report(self) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø–æ–ª–Ω—ã–π –æ—Ç—á–µ—Ç –∞–Ω–∞–ª–∏–∑–∞"""
        report = []
        report.append("=" * 80)
        report.append("üß† –ü–û–õ–ù–´–ô –û–¢–ß–ï–¢ –ê–ù–ê–õ–ò–ó–ê –ë–ê–ó–´ –ó–ù–ê–ù–ò–ô")
        report.append("=" * 80)
        report.append(f"üìÖ –î–∞—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report.append("")
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        report.append("üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –î–ê–ù–ù–´–•:")
        report.append(f"   ‚Ä¢ –ò–Ω–¥–∏–≤–∏–¥–æ–≤: {len(self.individuals_data)}")
        if self.trades_df is not None:
            report.append(f"   ‚Ä¢ –°–¥–µ–ª–æ–∫: {len(self.trades_df)}")
        if self.errors_df is not None:
            report.append(f"   ‚Ä¢ –û—à–∏–±–æ–∫: {len(self.errors_df)}")
        report.append("")
        
        # –ê–Ω–∞–ª–∏–∑ —É—Å–ø–µ—à–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
        success_patterns = self.analyze_successful_patterns()
        if success_patterns:
            report.append("‚úÖ –ê–ù–ê–õ–ò–ó –£–°–ü–ï–®–ù–´–• –ü–ê–¢–¢–ï–†–ù–û–í:")
            report.append(f"   ‚Ä¢ –û–±—â–∏–π winrate: {success_patterns['winrate']}%")
            report.append(f"   ‚Ä¢ –°—Ä–µ–¥–Ω–∏–π PnL: {success_patterns['avg_pnl']:.4f}")
            report.append(f"   ‚Ä¢ –û–±—â–∏–π PnL: {success_patterns['total_pnl']:.4f}")
            report.append("")
        
        # –ê–Ω–∞–ª–∏–∑ –æ—à–∏–±–æ–∫
        error_patterns = self.analyze_error_patterns()
        if error_patterns:
            report.append("‚ùå –ê–ù–ê–õ–ò–ó –û–®–ò–ë–û–ö:")
            report.append(f"   ‚Ä¢ –í—Å–µ–≥–æ –æ—à–∏–±–æ–∫: {error_patterns['total_errors']}")
            if 'error_types' in error_patterns:
                report.append("   ‚Ä¢ –¢–∏–ø—ã –æ—à–∏–±–æ–∫:")
                for error_type, count in error_patterns['error_types'].head(5).items():
                    report.append(f"     - {error_type}: {count}")
            report.append("")
        
        # –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        optimal_params = self.find_optimal_parameters()
        if optimal_params and 'recommendations' in optimal_params:
            report.append("üéØ –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:")
            for rec in optimal_params['recommendations']:
                report.append(f"   ‚Ä¢ {rec}")
            report.append("")
        
        report.append("=" * 80)
        return "\n".join(report)
    
    def save_analysis_report(self, filename: str = None):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –æ—Ç—á–µ—Ç –∞–Ω–∞–ª–∏–∑–∞ –≤ —Ñ–∞–π–ª"""
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = os.path.join(self.data_dir, f"analysis_report_{timestamp}.txt")
        
        report = self.generate_full_report()
        
        with open(filename, 'w', encoding='utf-8') as f:
            f.write(report)
        
        print(f"üìÑ –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {filename}")
        return filename 

    def save_trade(self, trade_data):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å–¥–µ–ª–∫—É –≤ —Ñ–∞–π–ª trades_YYYY-MM-DD.json —Å —Ä–æ—Ç–∞—Ü–∏–µ–π –ø–æ —Ä–∞–∑–º–µ—Ä—É"""
        date_str = datetime.now().strftime('%Y-%m-%d')
        base_name = f"trades_{date_str}.json"
        file_path = os.path.join('learning_data', base_name)
        part = 1
        while os.path.exists(file_path) and os.path.getsize(file_path) > 10*1024*1024:
            part += 1
            file_path = os.path.join('learning_data', f"trades_{date_str}_part{part}.json")
        with open(file_path, 'a', encoding='utf-8') as f:
            f.write(json.dumps(trade_data, ensure_ascii=False) + '\n')
    def save_error(self, error_data):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –æ—à–∏–±–∫—É –≤ —Ñ–∞–π–ª errors_YYYY-MM-DD.json —Å —Ä–æ—Ç–∞—Ü–∏–µ–π –ø–æ —Ä–∞–∑–º–µ—Ä—É"""
        date_str = datetime.now().strftime('%Y-%m-%d')
        base_name = f"errors_{date_str}.json"
        file_path = os.path.join('learning_data', base_name)
        part = 1
        while os.path.exists(file_path) and os.path.getsize(file_path) > 10*1024*1024:
            part += 1
            file_path = os.path.join('learning_data', f"errors_{date_str}_part{part}.json")
        with open(file_path, 'a', encoding='utf-8') as f:
            f.write(json.dumps(error_data, ensure_ascii=False) + '\n')
    def load_all_trades(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –≤—Å–µ —Å–¥–µ–ª–∫–∏ –∏–∑ –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤ trades_*.json"""
        trades = []
        for fname in os.listdir('learning_data'):
            if fname.startswith('trades_') and fname.endswith('.json'):
                with open(os.path.join('learning_data', fname), 'r', encoding='utf-8') as f:
                    for line in f:
                        try:
                            trades.append(json.loads(line))
                        except:
                            pass
        return trades
    def load_all_errors(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –≤—Å–µ –æ—à–∏–±–∫–∏ –∏–∑ –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤ errors_*.json"""
        errors = []
        for fname in os.listdir('learning_data'):
            if fname.startswith('errors_') and fname.endswith('.json'):
                with open(os.path.join('learning_data', fname), 'r', encoding='utf-8') as f:
                    for line in f:
                        try:
                            errors.append(json.loads(line))
                        except:
                            pass
        return errors 

    def get_learning_statistics(self) -> dict:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫—Ä–∞—Ç–∫—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –æ–±—É—á–µ–Ω–∏—è –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ UI –∏ –æ—Ç—á–µ—Ç–∞—Ö"""
        stats = {
            'generation': None,
            'total_trades': 0,
            'total_errors': 0,
            'avg_winrate': 0.0,
            'best_winrate': 0.0,
            'knowledge_base_size': 0
        }
        # –ü–æ–∫–æ–ª–µ–Ω–∏—è (–µ—Å–ª–∏ –µ—Å—Ç—å –∏–Ω–¥–∏–≤–∏–¥—ã)
        if self.individuals_data:
            generations = [ind.get('generation', 0) for ind in self.individuals_data]
            stats['generation'] = max(generations) if generations else None
        # –°–¥–µ–ª–∫–∏
        if self.trades_df is not None and not self.trades_df.empty:
            stats['total_trades'] = len(self.trades_df)
            winrates = self.trades_df.groupby('individual_id')['win'].mean().apply(lambda x: x * 100)
            stats['avg_winrate'] = float(winrates.mean()) if not winrates.empty else 0.0
            stats['best_winrate'] = float(winrates.max()) if not winrates.empty else 0.0
        # –û—à–∏–±–∫–∏
        if self.errors_df is not None and not self.errors_df.empty:
            stats['total_errors'] = len(self.errors_df)
        # –†–∞–∑–º–µ—Ä –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π
        stats['knowledge_base_size'] = len(self.knowledge_base) if self.knowledge_base else 0
        return stats

    def analyze_trade_result(self, trade_data: dict) -> str:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π —Å–¥–µ–ª–∫–∏"""
        if not trade_data:
            return "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"
        
        win = trade_data.get('win', False)
        pnl = trade_data.get('pnl', 0)
        symbol = trade_data.get('symbol', 'UNKNOWN')
        direction = trade_data.get('direction', 'UNKNOWN')
        
        if win:
            return f"‚úÖ –£—Å–ø–µ—à–Ω–∞—è —Å–¥–µ–ª–∫–∞ {symbol} {direction}: +${pnl:.2f}"
        else:
            return f"‚ùå –£–±—ã—Ç–æ—á–Ω–∞—è —Å–¥–µ–ª–∫–∞ {symbol} {direction}: ${pnl:.2f}"

    # === –°–ò–°–¢–ï–ú–ê –£–ú–ù–û–ì–û –£–ü–†–ê–í–õ–ï–ù–ò–Ø –ó–ù–ê–ù–ò–Ø–ú–ò ===
    
    def setup_knowledge_structure(self):
        """–°–æ–∑–¥–∞–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø–∞–ø–æ–∫ –¥–ª—è —É–º–Ω–æ–≥–æ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∑–Ω–∞–Ω–∏—è–º–∏"""
        folders = [
            'knowledge_data/current',      # –¢–µ–∫—É—â–∏–µ –∞–∫—Ç–∏–≤–Ω—ã–µ –∑–Ω–∞–Ω–∏—è
            'knowledge_data/archive',      # –ê—Ä—Ö–∏–≤ —É—Å–ø–µ—à–Ω—ã—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π
            'knowledge_data/experimental', # –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω—ã–µ –∑–Ω–∞–Ω–∏—è
            'knowledge_data/backup',       # –†–µ–∑–µ—Ä–≤–Ω—ã–µ –∫–æ–ø–∏–∏
            'knowledge_data/validated'     # –ü—Ä–æ–≤–µ—Ä–µ–Ω–Ω—ã–µ –∑–Ω–∞–Ω–∏—è
        ]
        
        for folder in folders:
            os.makedirs(folder, exist_ok=True)
        
        print("‚úÖ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø–∞–ø–æ–∫ –∑–Ω–∞–Ω–∏–π —Å–æ–∑–¥–∞–Ω–∞")
    
    def validate_knowledge_quality(self, knowledge_data: dict) -> dict:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ –∑–Ω–∞–Ω–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
        validation_result = {
            'is_valid': True,
            'score': 0.0,
            'issues': [],
            'recommendations': []
        }
        
        if not knowledge_data:
            validation_result['is_valid'] = False
            validation_result['issues'].append("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏")
            return validation_result
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º winrate
        total_trades = len(knowledge_data.get('trades', []))
        if total_trades > 0:
            wins = sum(1 for trade in knowledge_data['trades'] if trade.get('win', False))
            winrate = wins / total_trades
            
            if winrate < 0.4:
                validation_result['issues'].append(f"–ù–∏–∑–∫–∏–π winrate: {winrate:.1%}")
                validation_result['score'] -= 0.3
            elif winrate > 0.6:
                validation_result['score'] += 0.3
                validation_result['recommendations'].append("–í—ã—Å–æ–∫–∏–π winrate - —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Å—Ç—Ä–∞—Ç–µ–≥–∏—é")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–∏–±—ã–ª—å–Ω–æ—Å—Ç—å
        total_pnl = sum(trade.get('pnl', 0) for trade in knowledge_data.get('trades', []))
        if total_pnl < 0:
            validation_result['issues'].append(f"–û–±—â–∏–π —É–±—ã—Ç–æ–∫: ${total_pnl:.2f}")
            validation_result['score'] -= 0.4
        else:
            validation_result['score'] += 0.4
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ —Å–¥–µ–ª–æ–∫
        symbols = set(trade.get('symbol', '') for trade in knowledge_data.get('trades', []))
        if len(symbols) < 3:
            validation_result['issues'].append(f"–ú–∞–ª–æ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è: {len(symbols)} —Å–∏–º–≤–æ–ª–æ–≤")
            validation_result['score'] -= 0.1
        
        # –§–∏–Ω–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞
        validation_result['score'] = max(0.0, min(1.0, validation_result['score'] + 0.5))
        
        if validation_result['score'] < 0.3:
            validation_result['is_valid'] = False
            validation_result['recommendations'].append("–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –æ—á–∏—Å—Ç–∫–∞ –∑–Ω–∞–Ω–∏–π")
        
        return validation_result
    
    def rotate_knowledge(self, force_rotation: bool = False):
        """–í—ã–ø–æ–ª–Ω—è–µ—Ç —Ä–æ—Ç–∞—Ü–∏—é –∑–Ω–∞–Ω–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏—Ö –∫–∞—á–µ—Å—Ç–≤–∞"""
        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–µ–∫—É—â–∏–µ –∑–Ω–∞–Ω–∏—è
            current_knowledge = self.load_knowledge_base()
            
            # –í–∞–ª–∏–¥–∏—Ä—É–µ–º –∫–∞—á–µ—Å—Ç–≤–æ
            validation = self.validate_knowledge_quality(current_knowledge)
            
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            
            if validation['is_valid'] and not force_rotation:
                # –ó–Ω–∞–Ω–∏—è —Ö–æ—Ä–æ—à–∏–µ - –∞—Ä—Ö–∏–≤–∏—Ä—É–µ–º —É—Å–ø–µ—à–Ω—É—é –≤–µ—Ä—Å–∏—é
                archive_file = f"knowledge_data/archive/knowledge_success_{timestamp}.json"
                with open(archive_file, 'w', encoding='utf-8') as f:
                    json.dump(current_knowledge, f, indent=2, ensure_ascii=False)
                
                print(f"‚úÖ –ó–Ω–∞–Ω–∏—è –∞—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞–Ω—ã –∫–∞–∫ —É—Å–ø–µ—à–Ω—ã–µ: {archive_file}")
                print(f"üìä –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞: {validation['score']:.2f}")
                
            else:
                # –ó–Ω–∞–Ω–∏—è –ø–ª–æ—Ö–∏–µ –∏–ª–∏ –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è —Ä–æ—Ç–∞—Ü–∏—è
                backup_file = f"knowledge_data/backup/knowledge_backup_{timestamp}.json"
                with open(backup_file, 'w', encoding='utf-8') as f:
                    json.dump(current_knowledge, f, indent=2, ensure_ascii=False)
                
                # –û—á–∏—â–∞–µ–º —Ç–æ–ª—å–∫–æ –ø—Ä–æ–±–ª–µ–º–Ω—ã–µ —á–∞—Å—Ç–∏
                self._clean_problematic_knowledge(current_knowledge)
                
                print(f"üîÑ –†–æ—Ç–∞—Ü–∏—è –∑–Ω–∞–Ω–∏–π –≤—ã–ø–æ–ª–Ω–µ–Ω–∞")
                print(f"üìÅ –†–µ–∑–µ—Ä–≤–Ω–∞—è –∫–æ–ø–∏—è: {backup_file}")
                if validation['issues']:
                    print(f"‚ö†Ô∏è –ü—Ä–æ–±–ª–µ–º—ã: {', '.join(validation['issues'])}")
            
            return validation
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Ä–æ—Ç–∞—Ü–∏–∏ –∑–Ω–∞–Ω–∏–π: {e}")
            return None
    
    def _clean_problematic_knowledge(self, knowledge_data: dict):
        """–û—á–∏—â–∞–µ—Ç —Ç–æ–ª—å–∫–æ –ø—Ä–æ–±–ª–µ–º–Ω—ã–µ —á–∞—Å—Ç–∏ –∑–Ω–∞–Ω–∏–π, —Å–æ—Ö—Ä–∞–Ω—è—è –ø–æ–ª–µ–∑–Ω—ã–µ"""
        if not knowledge_data:
            return
        
        # –£–¥–∞–ª—è–µ–º —Å–¥–µ–ª–∫–∏ —Å –æ—á–µ–Ω—å –ø–ª–æ—Ö–∏–º–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
        if 'trades' in knowledge_data:
            good_trades = []
            for trade in knowledge_data['trades']:
                pnl = trade.get('pnl', 0)
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–¥–µ–ª–∫–∏ —Å —É–º–µ—Ä–µ–Ω–Ω—ã–º–∏ —É–±—ã—Ç–∫–∞–º–∏, —É–¥–∞–ª—è–µ–º –∫–∞—Ç–∞—Å—Ç—Ä–æ—Ñ–∏—á–µ—Å–∫–∏–µ
                if pnl > -50:  # –ù–µ —É–¥–∞–ª—è–µ–º —Å–¥–µ–ª–∫–∏ —Å —É–±—ã—Ç–∫–æ–º –±–æ–ª—å—à–µ $50
                    good_trades.append(trade)
            
            knowledge_data['trades'] = good_trades
            print(f"üßπ –û—á–∏—â–µ–Ω–æ {len(knowledge_data['trades']) - len(good_trades)} –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö —Å–¥–µ–ª–æ–∫")
        
        # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ –æ—à–∏–±–∫–∏ (—Å—Ç–∞—Ä—à–µ 7 –¥–Ω–µ–π)
        if 'errors' in knowledge_data:
            week_ago = datetime.now() - timedelta(days=7)
            recent_errors = []
            for error in knowledge_data['errors']:
                error_time = datetime.fromisoformat(error.get('timestamp', '2020-01-01'))
                if error_time > week_ago:
                    recent_errors.append(error)
            
            knowledge_data['errors'] = recent_errors
            print(f"üßπ –û—á–∏—â–µ–Ω–æ {len(knowledge_data['errors']) - len(recent_errors)} —Å—Ç–∞—Ä—ã—Ö –æ—à–∏–±–æ–∫")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—á–∏—â–µ–Ω–Ω—ã–µ –∑–Ω–∞–Ω–∏—è
        with open('knowledge_data/current/knowledge_cleaned.json', 'w', encoding='utf-8') as f:
            json.dump(knowledge_data, f, indent=2, ensure_ascii=False)
    
    def get_knowledge_statistics(self) -> dict:
        """–ü–æ–ª—É—á–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –≤—Å–µ–º –∑–Ω–∞–Ω–∏—è–º"""
        stats = {
            'current': {'files': 0, 'size_mb': 0},
            'archive': {'files': 0, 'size_mb': 0},
            'experimental': {'files': 0, 'size_mb': 0},
            'backup': {'files': 0, 'size_mb': 0},
            'validated': {'files': 0, 'size_mb': 0}
        }
        
        for folder in stats.keys():
            folder_path = f"knowledge_data/{folder}"
            if os.path.exists(folder_path):
                files = os.listdir(folder_path)
                stats[folder]['files'] = len(files)
                
                total_size = 0
                for file in files:
                    file_path = os.path.join(folder_path, file)
                    if os.path.isfile(file_path):
                        total_size += os.path.getsize(file_path)
                
                stats[folder]['size_mb'] = round(total_size / (1024 * 1024), 2)
        
        return stats
    
    def auto_cleanup_old_knowledge(self, days_old: int = 30):
        """–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —É–¥–∞–ª—è–µ—Ç —Å—Ç–∞—Ä—ã–µ –∑–Ω–∞–Ω–∏—è"""
        cutoff_date = datetime.now() - timedelta(days=days_old)
        deleted_count = 0
        
        for folder in ['backup', 'experimental']:
            folder_path = f"knowledge_data/{folder}"
            if not os.path.exists(folder_path):
                continue
            
            for filename in os.listdir(folder_path):
                file_path = os.path.join(folder_path, filename)
                if os.path.isfile(file_path):
                    file_time = datetime.fromtimestamp(os.path.getctime(file_path))
                    if file_time < cutoff_date:
                        os.remove(file_path)
                        deleted_count += 1
        
        if deleted_count > 0:
            print(f"üßπ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —É–¥–∞–ª–µ–Ω–æ {deleted_count} —Å—Ç–∞—Ä—ã—Ö —Ñ–∞–π–ª–æ–≤ –∑–Ω–∞–Ω–∏–π")
        
        return deleted_count 

    def load_knowledge(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –≤—Å–µ –∑–Ω–∞–Ω–∏—è –∏–∑ knowledge_data/ –≤ DataFrame"""
        data_dir = os.path.join(os.path.dirname(__file__), 'knowledge_data')
        all_trades = []
        for root, dirs, files in os.walk(data_dir):
            for file in files:
                if file.endswith('.csv') or file.endswith('.parquet'):
                    file_path = os.path.join(root, file)
                    try:
                        if file.endswith('.csv'):
                            df = pd.read_csv(file_path)
                        else:
                            df = pd.read_parquet(file_path)
                        all_trades.append(df)
                    except Exception as e:
                        print(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è {file_path}: {e}")
        if all_trades:
            self.trades_df = pd.concat(all_trades, ignore_index=True)
        else:
            self.trades_df = pd.DataFrame()
        return self.trades_df 