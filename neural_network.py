"""
üß† –ê–≤—Ç–æ–Ω–æ–º–Ω–∞—è –Ω–µ–π—Ä–æ—Å–µ—Ç—å –¥–ª—è —Ä–∏—Å–∫-–º–µ–Ω–µ–¥–∂–º–µ–Ω—Ç–∞ –∏ –º–∞–Ω–∏-–º–µ–Ω–µ–¥–∂–º–µ–Ω—Ç–∞
–û–±—É—á–µ–Ω–∏–µ –º–µ—Ç–æ–¥–æ–º –ø—Ä–æ–± –∏ –æ—à–∏–±–æ–∫ –¥–ª—è –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è –≤–∏–Ω—Ä–µ–π—Ç–∞ 70%+
"""

import numpy as np
import pandas as pd
import random
import json
import time
from datetime import datetime, timedelta
from typing import Dict, List, Tuple, Optional
import os

class AutonomousNeuralNetwork:
    """–ê–≤—Ç–æ–Ω–æ–º–Ω–∞—è –Ω–µ–π—Ä–æ—Å–µ—Ç—å –¥–ª—è —Ç–æ—Ä–≥–æ–≤–ª–∏ –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç–∞–º–∏"""
    
    def __init__(self, initial_capital: float = 100.0):
        self.initial_capital = initial_capital
        self.current_capital = initial_capital
        self.learning_rate = 0.01
        self.experience_memory = []
        self.success_patterns = []
        self.failure_patterns = []
        self.current_cycle = 0
        self.total_trades = 0
        self.profitable_trades = 0
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –∞–≤—Ç–æ–Ω–æ–º–Ω–æ–≥–æ –ø—Ä–∏–Ω—è—Ç–∏—è —Ä–µ—à–µ–Ω–∏–π
        self.position_size_range = (0.01, 1.0)  # 1-100% –æ—Ç –∫–∞–ø–∏—Ç–∞–ª–∞
        self.leverage_range = (1, 20)  # 1x-20x –ø–ª–µ—á–æ
        self.stop_loss_range = (0.001, 0.5)  # 0.1%-50%
        self.take_profit_range = (0.005, 2.0)  # 0.5%-200%
        
        # –ù–µ–π—Ä–æ–Ω–Ω—ã–µ –≤–µ—Å–∞ (—É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å)
        self.weights = {
            'price_data': np.random.randn(10),
            'volume_data': np.random.randn(10),
            'time_data': np.random.randn(10),
            'risk_appetite': np.random.randn(10),
            'market_conditions': np.random.randn(10)
        }
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ–±—É—á–µ–Ω–∏—è
        self.learning_stats = {
            'cycles_completed': 0,
            'total_profit': 0.0,
            'max_drawdown': 0.0,
            'win_rate_history': [],
            'capital_history': [initial_capital]
        }

        self.exploration_rate = 1.0  # –ù–∞—á–∏–Ω–∞–µ–º —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —Å–ª—É—á–∞–π–Ω–æ—Å—Ç–∏
        self.exploration_decay = 0.995  # –ú–µ–¥–ª–µ–Ω–Ω–æ —É–º–µ–Ω—å—à–∞–µ–º —Å–ª—É—á–∞–π–Ω–æ—Å—Ç—å
        self.min_exploration = 0.05  # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —É—Ä–æ–≤–µ–Ω—å —Å–ª—É—á–∞–π–Ω–æ—Å—Ç–∏
        
        # üß† –ù–û–í–´–ï –ú–ï–•–ê–ù–ò–ó–ú–´ –î–õ–Ø –ü–û–í–´–®–ï–ù–ò–Ø –í–ò–ù–†–ï–ô–¢–ê
        # 1. –£–º–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –Ω–∞ –ø–∞—Ç—Ç–µ—Ä–Ω–∞—Ö
        self.pattern_learning = {
            'successful_conditions': [],  # –£—Å–ª–æ–≤–∏—è —É—Å–ø–µ—à–Ω—ã—Ö —Å–¥–µ–ª–æ–∫
            'failure_conditions': [],     # –£—Å–ª–æ–≤–∏—è –Ω–µ—É–¥–∞—á–Ω—ã—Ö —Å–¥–µ–ª–æ–∫
            'pattern_weights': {},        # –í–µ—Å–∞ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
            'pattern_confidence': 0.0     # –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ –ø–∞—Ç—Ç–µ—Ä–Ω–∞—Ö
        }
        
        # 2. –®—Ç—Ä–∞—Ñ—ã –∑–∞ —á–∞—Å—Ç—ã–µ —É–±—ã—Ç–∫–∏
        self.loss_penalty = {
            'consecutive_losses': 0,      # –ü–æ–¥—Ä—è–¥ —É–±—ã—Ç–∫–æ–≤
            'max_consecutive_losses': 5,  # –ú–∞–∫—Å–∏–º—É–º –ø–æ–¥—Ä—è–¥ —É–±—ã—Ç–∫–æ–≤
            'penalty_multiplier': 1.0,    # –ú–Ω–æ–∂–∏—Ç–µ–ª—å —à—Ç—Ä–∞—Ñ–∞
            'recovery_threshold': 3       # –£–±—ã—Ç–∫–æ–≤ –¥–ª—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è
        }
        
        # 3. –ê–¥–∞–ø—Ç–∏–≤–Ω–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è
        self.adaptive_strategy = {
            'current_performance': 0.0,   # –¢–µ–∫—É—â–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
            'strategy_confidence': 0.5,   # –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
            'adaptation_rate': 0.1,       # –°–∫–æ—Ä–æ—Å—Ç—å –∞–¥–∞–ø—Ç–∞—Ü–∏–∏
            'performance_history': []     # –ò—Å—Ç–æ—Ä–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        }
    
    def make_autonomous_decision(self, market_data: Dict) -> Dict:
        """–ü—Ä–∏–Ω–∏–º–∞–µ—Ç –∞–≤—Ç–æ–Ω–æ–º–Ω–æ–µ —Ç–æ—Ä–≥–æ–≤–æ–µ —Ä–µ—à–µ–Ω–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å—ã—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö —Å —É–º–Ω—ã–º –æ–±—É—á–µ–Ω–∏–µ–º"""
        
        # üß† 1. –£–ú–ù–û–ï –û–ë–£–ß–ï–ù–ò–ï –ù–ê –ü–ê–¢–¢–ï–†–ù–ê–•
        pattern_decision = self._get_pattern_based_decision(market_data)
        
        # üß† 2. –®–¢–†–ê–§–´ –ó–ê –ß–ê–°–¢–´–ï –£–ë–´–¢–ö–ò - —Å–Ω–∏–∂–∞–µ–º exploration –ø—Ä–∏ –ø–ª–æ—Ö–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö
        adjusted_exploration_rate = self._adjust_exploration_for_losses()
        
        # Exploration: —Å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é adjusted_exploration_rate –ø—Ä–∏–Ω–∏–º–∞–µ–º —Å–ª—É—á–∞–π–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ
        if random.random() < adjusted_exploration_rate:
            decision = {
                'action': random.choice(['buy', 'sell']),
                'position_size': min(random.uniform(*self.position_size_range), 0.2),  # –º–∞–∫—Å–∏–º—É–º 20%
                'leverage': min(random.randint(*self.leverage_range), 10),  # –º–∞–∫—Å–∏–º—É–º 10x
                'stop_loss': random.uniform(*self.stop_loss_range),
                'take_profit': random.uniform(*self.take_profit_range),
                'timeframe': random.choice(['3m', '5m', '15m', '30m', '1h', '2h', '4h', '6h', '8h', '12h', '1d', '1w', '1M']),
                'confidence': random.uniform(0, 1),
                'exploration': True
            }
        else:
            # üß† 3. –ê–î–ê–ü–¢–ò–í–ù–ê–Ø –°–¢–†–ê–¢–ï–ì–ò–Ø - –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã –∏ –∞–¥–∞–ø—Ç–∏—Ä—É–µ–º—Å—è
            decision = self._get_adaptive_decision(market_data, pattern_decision)
            decision['exploration'] = False
            # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –¥–ª—è –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–≥–æ —Ä–µ—à–µ–Ω–∏—è
            decision['position_size'] = min(decision.get('position_size', 0.05), 0.2)
            decision['leverage'] = min(decision.get('leverage', 1), 10)
        
        return decision
    
    def _decide_action(self, market_data: Dict) -> str:
        """–†–µ—à–µ–Ω–∏–µ –æ –¥–µ–π—Å—Ç–≤–∏–∏: buy, sell –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å—ã—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
        # –ù–µ–π—Ä–æ—Å–µ—Ç—å —É—á–∏—Ç—Å—è –ø—Ä–∏–Ω–∏–º–∞—Ç—å —Ä–µ—à–µ–Ω–∏—è —Ç–æ–ª—å–∫–æ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ü–µ–Ω—ã, –æ–±—ä–µ–º–∞ –∏ –≤—Ä–µ–º–µ–Ω–∏
        # –ù–∏–∫–∞–∫–∏—Ö –≥–æ—Ç–æ–≤—ã—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤!
        
        # –ü—Ä–æ—Å—Ç–∞—è –ª–æ–≥–∏–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å—ã—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        close_price = market_data.get('close', 0)
        volume = market_data.get('volume', 0)
        hour = market_data.get('hour_of_day', 12)
        
        # –°–ª—É—á–∞–π–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ (–Ω–µ–π—Ä–æ—Å–µ—Ç—å –±—É–¥–µ—Ç —É—á–∏—Ç—å—Å—è —á–µ—Ä–µ–∑ –æ—à–∏–±–∫–∏)
        action_score = random.uniform(-1, 1)
        
        if action_score > 0:
            return 'buy'
        else:
            return 'sell'
    
    def _decide_position_size(self) -> float:
        """–ê–≤—Ç–æ–Ω–æ–º–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ –æ —Ä–∞–∑–º–µ—Ä–µ –ø–æ–∑–∏—Ü–∏–∏"""
        # –ù–µ–π—Ä–æ—Å–µ—Ç—å —É—á–∏—Ç—Å—è –≤—ã–±–∏—Ä–∞—Ç—å –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä
        base_size = random.uniform(*self.position_size_range)
        
        # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ–ø—ã—Ç–∞
        if self.learning_stats['win_rate_history']:
            recent_win_rate = np.mean(self.learning_stats['win_rate_history'][-10:])
            if recent_win_rate > 0.6:
                base_size *= 1.2  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä –ø—Ä–∏ —Ö–æ—Ä–æ—à–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö
            elif recent_win_rate < 0.4:
                base_size *= 0.8  # –£–º–µ–Ω—å—à–∞–µ–º –ø—Ä–∏ –ø–ª–æ—Ö–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö
        
        return min(base_size, 1.0)  # –ú–∞–∫—Å–∏–º—É–º 100% –∫–∞–ø–∏—Ç–∞–ª–∞
    
    def _decide_leverage(self) -> int:
        """–ê–≤—Ç–æ–Ω–æ–º–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ –æ –ø–ª–µ—á–µ"""
        # –ù–µ–π—Ä–æ—Å–µ—Ç—å —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∏—Ä—É–µ—Ç —Å —Ä–∞–∑–Ω—ã–º–∏ –ø–ª–µ—á–∞–º–∏
        leverage = random.randint(*self.leverage_range)
        
        # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–∏—Å–∫–∞
        if self.current_capital < self.initial_capital * 0.8:  # –ü—Ä–æ—Å–∞–¥–∫–∞
            leverage = max(leverage // 2, 1)  # –£–º–µ–Ω—å—à–∞–µ–º –ø–ª–µ—á–æ
        
        return leverage
    
    def _decide_stop_loss(self) -> float:
        """–ê–≤—Ç–æ–Ω–æ–º–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ –æ —Å—Ç–æ–ø-–ª–æ—Å—Å–µ"""
        return random.uniform(*self.stop_loss_range)
    
    def _decide_take_profit(self) -> float:
        """–ê–≤—Ç–æ–Ω–æ–º–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ –æ —Ç–µ–π–∫-–ø—Ä–æ—Ñ–∏—Ç–µ"""
        return random.uniform(*self.take_profit_range)
    
    def _decide_timeframe(self) -> str:
        """–ê–≤—Ç–æ–Ω–æ–º–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ –æ —Ç–∞–π–º—Ñ—Ä–µ–π–º–µ"""
        timeframes = ['3m', '5m', '15m', '30m', '1h', '2h', '4h', '6h', '8h', '12h', '1d', '1w', '1M']
        return random.choice(timeframes)
    
    def _calculate_confidence(self, market_data: Dict) -> float:
        """–†–∞—Å—á–µ—Ç —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –≤ —Ä–µ—à–µ–Ω–∏–∏"""
        # –ü—Ä–æ—Å—Ç–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å—ã—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        confidence = random.uniform(0, 1)
        return confidence
    
    def learn_from_result(self, decision: Dict, result: Dict):
        """–û–±—É—á–µ–Ω–∏–µ –Ω–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ —Å–¥–µ–ª–∫–∏ —Å –Ω–æ–≤—ã–º–∏ –º–µ—Ö–∞–Ω–∏–∑–º–∞–º–∏"""
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–ø—ã—Ç
        experience = {
            'decision': decision,
            'result': result,
            'timestamp': datetime.now().isoformat(),
            'cycle': self.current_cycle
        }
        self.experience_memory.append(experience)
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Å –∑–∞—â–∏—Ç–æ–π –æ—Ç nan
        profit = float(result.get('profit', 0))
        if np.isnan(profit):
            profit = 0.0
        
        self.total_trades += 1
        if profit > 0:
            self.profitable_trades += 1
            self.success_patterns.append(decision)
            
            # üß† 1. –£–ú–ù–û–ï –û–ë–£–ß–ï–ù–ò–ï –ù–ê –ü–ê–¢–¢–ï–†–ù–ê–• - —Å–æ—Ö—Ä–∞–Ω—è–µ–º —É—Å–ø–µ—à–Ω—ã–µ —É—Å–ª–æ–≤–∏—è
            market_conditions = self._extract_market_conditions(result.get('market_data', {}))
            successful_pattern = {
                'conditions': market_conditions,
                'decision': decision,
                'profit': profit,
                'timestamp': datetime.now().isoformat()
            }
            self.pattern_learning['successful_conditions'].append(successful_pattern)
            
            # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å—á–µ—Ç—á–∏–∫ —É–±—ã—Ç–∫–æ–≤ –ø—Ä–∏ –ø—Ä–∏–±—ã–ª–∏
            self.loss_penalty['consecutive_losses'] = 0
            
        else:
            self.failure_patterns.append(decision)
            
            # üß† 2. –®–¢–†–ê–§–´ –ó–ê –ß–ê–°–¢–´–ï –£–ë–´–¢–ö–ò - –æ—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º –ø–æ–¥—Ä—è–¥ —É–±—ã—Ç–∫–∏
            self.loss_penalty['consecutive_losses'] += 1
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–µ—É–¥–∞—á–Ω—ã–µ —É—Å–ª–æ–≤–∏—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            market_conditions = self._extract_market_conditions(result.get('market_data', {}))
            failure_pattern = {
                'conditions': market_conditions,
                'decision': decision,
                'loss': abs(profit),
                'timestamp': datetime.now().isoformat()
            }
            self.pattern_learning['failure_conditions'].append(failure_pattern)
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –∫–∞–ø–∏—Ç–∞–ª —Å –∑–∞—â–∏—Ç–æ–π –æ—Ç nan
        self.current_capital += profit
        if np.isnan(self.current_capital):
            self.current_capital = self.initial_capital
        
        self.learning_stats['total_profit'] += profit
        if np.isnan(self.learning_stats['total_profit']):
            self.learning_stats['total_profit'] = 0.0
        
        self.learning_stats['capital_history'].append(self.current_capital)
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –≤–∏–Ω—Ä–µ–π—Ç
        current_win_rate = self.profitable_trades / self.total_trades
        self.learning_stats['win_rate_history'].append(current_win_rate)
        
        # üß† 3. –ê–î–ê–ü–¢–ò–í–ù–ê–Ø –°–¢–†–ê–¢–ï–ì–ò–Ø - –æ–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
        self._update_adaptive_strategy(profit, current_win_rate)
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –ø—Ä–æ—Å–∞–¥–∫—É
        max_capital = max(self.learning_stats['capital_history'])
        current_drawdown = (max_capital - self.current_capital) / max_capital
        self.learning_stats['max_drawdown'] = max(self.learning_stats['max_drawdown'], current_drawdown)
        
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä –ø–∞–º—è—Ç–∏ - –£–õ–£–ß–®–ï–ù–ù–ê–Ø –í–ï–†–°–ò–Ø
        if len(self.experience_memory) > 50000:  # –£–≤–µ–ª–∏—á–∏–ª–∏ —Å 10000 –¥–æ 50000
            self.experience_memory = self.experience_memory[-25000:]  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –±–æ–ª—å—à–µ
        
        if len(self.success_patterns) > 2000:  # –£–≤–µ–ª–∏—á–∏–ª–∏ —Å 1000 –¥–æ 2000
            self.success_patterns = self.success_patterns[-1000:]  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –±–æ–ª—å—à–µ
        
        if len(self.failure_patterns) > 2000:  # –£–≤–µ–ª–∏—á–∏–ª–∏ —Å 1000 –¥–æ 2000
            self.failure_patterns = self.failure_patterns[-1000:]  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –±–æ–ª—å—à–µ
        
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã - –£–õ–£–ß–®–ï–ù–ù–ê–Ø –í–ï–†–°–ò–Ø
        if len(self.pattern_learning['successful_conditions']) > 1000:  # –£–≤–µ–ª–∏—á–∏–ª–∏ —Å 500 –¥–æ 1000
            self.pattern_learning['successful_conditions'] = self.pattern_learning['successful_conditions'][-500:]  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –±–æ–ª—å—à–µ
        
        if len(self.pattern_learning['failure_conditions']) > 1000:  # –£–≤–µ–ª–∏—á–∏–ª–∏ —Å 500 –¥–æ 1000
            self.pattern_learning['failure_conditions'] = self.pattern_learning['failure_conditions'][-500:]  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –±–æ–ª—å—à–µ
        
        # –£–º–µ–Ω—å—à–∞–µ–º exploration rate
        self.exploration_rate = max(self.min_exploration, self.exploration_rate * self.exploration_decay)
    
    def _update_adaptive_strategy(self, profit: float, win_rate: float):
        """–û–±–Ω–æ–≤–ª—è–µ—Ç –∞–¥–∞–ø—Ç–∏–≤–Ω—É—é —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
        # –û–±–Ω–æ–≤–ª—è–µ–º —Ç–µ–∫—É—â—É—é –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
        performance_score = 0.0
        
        # 50% –≤–µ—Å–∞ –¥–ª—è –≤–∏–Ω—Ä–µ–π—Ç–∞
        performance_score += win_rate * 0.5
        
        # 30% –≤–µ—Å–∞ –¥–ª—è –ø—Ä–∏–±—ã–ª—å–Ω–æ—Å—Ç–∏ (–Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–π)
        if self.total_trades > 0:
            avg_profit = self.learning_stats['total_profit'] / self.total_trades
            normalized_profit = min(1.0, max(-1.0, avg_profit / 10.0))  # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∫ ¬±10$
            performance_score += (normalized_profit + 1.0) * 0.15  # –°–¥–≤–∏–≥–∞–µ–º –∫ 0-1
        
        # 20% –≤–µ—Å–∞ –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ –∫–∞–ø–∏—Ç–∞–ª–∞
        if len(self.learning_stats['capital_history']) > 10:
            recent_capital = self.learning_stats['capital_history'][-10:]
            capital_stability = 1.0 - (max(recent_capital) - min(recent_capital)) / max(recent_capital)
            performance_score += capital_stability * 0.2
        
        self.adaptive_strategy['current_performance'] = performance_score
        self.adaptive_strategy['performance_history'].append(performance_score)
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
        if len(self.adaptive_strategy['performance_history']) > 10:
            recent_performance = self.adaptive_strategy['performance_history'][-10:]
            avg_performance = np.mean(recent_performance)
            
            if avg_performance > 0.6:
                self.adaptive_strategy['strategy_confidence'] = min(1.0, self.adaptive_strategy['strategy_confidence'] + 0.1)
            elif avg_performance < 0.4:
                self.adaptive_strategy['strategy_confidence'] = max(0.1, self.adaptive_strategy['strategy_confidence'] - 0.1)
        
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        if len(self.adaptive_strategy['performance_history']) > 100:
            self.adaptive_strategy['performance_history'] = self.adaptive_strategy['performance_history'][-50:]
    
    def get_learning_stats(self) -> Dict:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –æ–±—É—á–µ–Ω–∏—è —Å –Ω–æ–≤—ã–º–∏ –º–µ—Ö–∞–Ω–∏–∑–º–∞–º–∏"""
        current_capital = float(self.current_capital or 100.0)
        if np.isnan(current_capital):
            current_capital = 100.0
        
        current_win_rate = self.profitable_trades / self.total_trades if self.total_trades > 0 else 0.0
        if np.isnan(current_win_rate):
            current_win_rate = 0.0
        
        return {
            'current_capital': current_capital,
            'total_profit': self.learning_stats['total_profit'],
            'total_trades': self.total_trades,
            'profitable_trades': self.profitable_trades,
            'win_rate': current_win_rate,
            'max_drawdown': self.learning_stats['max_drawdown'],
            'cycles_completed': self.learning_stats['cycles_completed'],
            'experience_memory_size': len(self.experience_memory),
            'success_patterns_count': len(self.success_patterns),
            'failure_patterns_count': len(self.failure_patterns),
            
            # üß† –ù–æ–≤—ã–µ –º–µ—Ö–∞–Ω–∏–∑–º—ã
            'exploration_rate': self.exploration_rate,
            'pattern_confidence': self.pattern_learning['pattern_confidence'],
            'consecutive_losses': self.loss_penalty['consecutive_losses'],
            'strategy_confidence': self.adaptive_strategy['strategy_confidence'],
            'current_performance': self.adaptive_strategy['current_performance'],
            'successful_patterns_stored': len(self.pattern_learning['successful_conditions']),
            'failure_patterns_stored': len(self.pattern_learning['failure_conditions'])
        }
    
    def save_state(self, filename: str = 'neural_network_state.json'):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ —Å –Ω–æ–≤—ã–º–∏ –º–µ—Ö–∞–Ω–∏–∑–º–∞–º–∏ - –£–õ–£–ß–®–ï–ù–ù–ê–Ø –í–ï–†–°–ò–Ø"""
        state = {
            'initial_capital': self.initial_capital,
            'current_capital': self.current_capital,
            'learning_rate': self.learning_rate,
            'experience_memory': self.experience_memory[-5000:],  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 5000 –æ–ø—ã—Ç–æ–≤ (—É–≤–µ–ª–∏—á–∏–ª–∏)
            'success_patterns': self.success_patterns[-1000:],    # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 1000 —É—Å–ø–µ—à–Ω—ã—Ö (—É–≤–µ–ª–∏—á–∏–ª–∏)
            'failure_patterns': self.failure_patterns[-1000:],    # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 1000 –Ω–µ—É–¥–∞—á–Ω—ã—Ö (—É–≤–µ–ª–∏—á–∏–ª–∏)
            'current_cycle': self.current_cycle,
            'total_trades': self.total_trades,
            'profitable_trades': self.profitable_trades,
            'weights': self.weights,
            'learning_stats': self.learning_stats,
            'exploration_rate': self.exploration_rate,
            
            # üß† –ù–æ–≤—ã–µ –º–µ—Ö–∞–Ω–∏–∑–º—ã
            'pattern_learning': self.pattern_learning,
            'loss_penalty': self.loss_penalty,
            'adaptive_strategy': self.adaptive_strategy
        }
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(state, f, indent=2, ensure_ascii=False, default=str)
    
    def get_state(self) -> Dict:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è –Ω–µ–π—Ä–æ—Å–µ—Ç–∏"""
        return {
            'initial_capital': self.initial_capital,
            'current_capital': self.current_capital,
            'learning_rate': self.learning_rate,
            'experience_memory_size': len(self.experience_memory),
            'success_patterns_count': len(self.success_patterns),
            'failure_patterns_count': len(self.failure_patterns),
            'current_cycle': self.current_cycle,
            'total_trades': self.total_trades,
            'profitable_trades': self.profitable_trades,
            'learning_stats': self.learning_stats,
            'exploration_rate': self.exploration_rate,
            
            # üß† –ù–æ–≤—ã–µ –º–µ—Ö–∞–Ω–∏–∑–º—ã
            'pattern_learning': self.pattern_learning,
            'loss_penalty': self.loss_penalty,
            'adaptive_strategy': self.adaptive_strategy
        }
    
    def load_state(self, state: Dict):
        """–ó–∞–≥—Ä—É–∑–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ —Å –Ω–æ–≤—ã–º–∏ –º–µ—Ö–∞–Ω–∏–∑–º–∞–º–∏"""
        if 'initial_capital' in state:
            self.initial_capital = state['initial_capital']
        if 'current_capital' in state:
            self.current_capital = state['current_capital']
        if 'learning_rate' in state:
            self.learning_rate = state['learning_rate']
        if 'experience_memory' in state:
            self.experience_memory = state['experience_memory']
        if 'success_patterns' in state:
            self.success_patterns = state['success_patterns']
        if 'failure_patterns' in state:
            self.failure_patterns = state['failure_patterns']
        if 'current_cycle' in state:
            self.current_cycle = state['current_cycle']
        if 'total_trades' in state:
            self.total_trades = state['total_trades']
        if 'profitable_trades' in state:
            self.profitable_trades = state['profitable_trades']
        if 'weights' in state:
            self.weights = state['weights']
        if 'learning_stats' in state:
            self.learning_stats = state['learning_stats']
        if 'exploration_rate' in state:
            self.exploration_rate = state['exploration_rate']
        
        # üß† –ù–æ–≤—ã–µ –º–µ—Ö–∞–Ω–∏–∑–º—ã
        if 'pattern_learning' in state:
            self.pattern_learning = state['pattern_learning']
        if 'loss_penalty' in state:
            self.loss_penalty = state['loss_penalty']
        if 'adaptive_strategy' in state:
            self.adaptive_strategy = state['adaptive_strategy']
    
    def _get_pattern_based_decision(self, market_data: Dict) -> Optional[Dict]:
        """–ü–æ–ª—É—á–∞–µ—Ç —Ä–µ—à–µ–Ω–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏–∑—É—á–µ–Ω–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤"""
        if not self.pattern_learning['successful_conditions']:
            return None
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–µ–∫—É—â–∏–µ —É—Å–ª–æ–≤–∏—è —Ä—ã–Ω–∫–∞
        current_conditions = self._extract_market_conditions(market_data)
        
        # –ò—â–µ–º –ø–æ—Ö–æ–∂–∏–µ —É—Å–ø–µ—à–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
        best_pattern = None
        best_similarity = 0.0
        
        for pattern in self.pattern_learning['successful_conditions'][-50:]:  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 50 —É—Å–ø–µ—à–Ω—ã—Ö
            similarity = self._calculate_pattern_similarity(current_conditions, pattern)
            if similarity > best_similarity and similarity > 0.7:  # –ú–∏–Ω–∏–º—É–º 70% —Å—Ö–æ–∂–µ—Å—Ç–∏
                best_similarity = similarity
                best_pattern = pattern
        
        if best_pattern:
            self.pattern_learning['pattern_confidence'] = best_similarity
            return best_pattern['decision']
        
        return None
    
    def _extract_market_conditions(self, market_data: Dict) -> Dict:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —É—Å–ª–æ–≤–∏—è —Ä—ã–Ω–∫–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤"""
        return {
            'price_level': market_data.get('close', 0),
            'volume_level': market_data.get('volume', 0),
            'hour_of_day': market_data.get('hour_of_day', 12),
            'day_of_week': market_data.get('day_of_week', 1),
            'price_change': market_data.get('price_change', 0),
            'volume_change': market_data.get('volume_change', 0)
        }
    
    def _calculate_pattern_similarity(self, current: Dict, pattern: Dict) -> float:
        """–í—ã—á–∏—Å–ª—è–µ—Ç —Å—Ö–æ–∂–µ—Å—Ç—å —Ç–µ–∫—É—â–∏—Ö —É—Å–ª–æ–≤–∏–π —Å –ø–∞—Ç—Ç–µ—Ä–Ω–æ–º"""
        if not pattern.get('conditions'):
            return 0.0
        
        similarities = []
        pattern_conditions = pattern['conditions']
        
        for key in current:
            if key in pattern_conditions:
                # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
                current_val = float(current[key])
                pattern_val = float(pattern_conditions[key])
                
                # –ü—Ä–æ—Å—Ç–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ (–º–æ–∂–Ω–æ —É–ª—É—á—à–∏—Ç—å)
                if pattern_val != 0:
                    similarity = 1.0 - abs(current_val - pattern_val) / abs(pattern_val)
                    similarities.append(max(0.0, similarity))
        
        return float(np.mean(similarities)) if similarities else 0.0
    
    def _adjust_exploration_for_losses(self) -> float:
        """–ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ—Ç exploration rate –Ω–∞ –æ—Å–Ω–æ–≤–µ —à—Ç—Ä–∞—Ñ–æ–≤ –∑–∞ —É–±—ã—Ç–∫–∏"""
        base_exploration = self.exploration_rate
        
        # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º exploration –ø—Ä–∏ —á–∞—Å—Ç—ã—Ö —É–±—ã—Ç–∫–∞—Ö
        if self.loss_penalty['consecutive_losses'] >= self.loss_penalty['max_consecutive_losses']:
            penalty_multiplier = 1.5  # –ë–æ–ª—å—à–µ —Å–ª—É—á–∞–π–Ω–æ—Å—Ç–∏ –ø—Ä–∏ –ø–ª–æ—Ö–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö
        elif self.loss_penalty['consecutive_losses'] >= self.loss_penalty['recovery_threshold']:
            penalty_multiplier = 1.2  # –£–º–µ—Ä–µ–Ω–Ω–æ –±–æ–ª—å—à–µ —Å–ª—É—á–∞–π–Ω–æ—Å—Ç–∏
        else:
            penalty_multiplier = 1.0  # –ù–æ—Ä–º–∞–ª—å–Ω—ã–π —É—Ä–æ–≤–µ–Ω—å
        
        adjusted_exploration = min(1.0, base_exploration * penalty_multiplier)
        return adjusted_exploration
    
    def _get_adaptive_decision(self, market_data: Dict, pattern_decision: Optional[Dict]) -> Dict:
        """–ü–æ–ª—É—á–∞–µ—Ç –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–∫—É—â–µ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        
        # –ï—Å–ª–∏ –µ—Å—Ç—å —É—Å–ø–µ—à–Ω—ã–π –ø–∞—Ç—Ç–µ—Ä–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ —Å –∞–¥–∞–ø—Ç–∞—Ü–∏–µ–π
        if pattern_decision and self.pattern_learning['pattern_confidence'] > 0.7:
            decision = pattern_decision.copy()
            
            # –ê–¥–∞–ø—Ç–∏—Ä—É–µ–º —Ä–∞–∑–º–µ—Ä –ø–æ–∑–∏—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
            confidence_factor = self.pattern_learning['pattern_confidence']
            decision['position_size'] *= confidence_factor
            
            # –ê–¥–∞–ø—Ç–∏—Ä—É–µ–º –ø–ª–µ—á–æ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            if self.adaptive_strategy['current_performance'] > 0.6:
                decision['leverage'] = min(decision['leverage'] + 1, 20)
            elif self.adaptive_strategy['current_performance'] < 0.4:
                decision['leverage'] = max(decision['leverage'] - 1, 1)
            
            decision['confidence'] = confidence_factor
            return decision
        
        # –ò–Ω–∞—á–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—É—é –ª–æ–≥–∏–∫—É —Å –∞–¥–∞–ø—Ç–∞—Ü–∏–µ–π
        decision = {
            'action': self._decide_action(market_data),
            'position_size': self._decide_position_size(),
            'leverage': self._decide_leverage(),
            'stop_loss': self._decide_stop_loss(),
            'take_profit': self._decide_take_profit(),
            'timeframe': self._decide_timeframe(),
            'confidence': self._calculate_confidence(market_data)
        }
        
        # –ê–¥–∞–ø—Ç–∏—Ä—É–µ–º –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        self._adapt_decision_parameters(decision)
        
        return decision
    
    def _adapt_decision_parameters(self, decision: Dict):
        """–ê–¥–∞–ø—Ç–∏—Ä—É–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Ä–µ—à–µ–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        performance = self.adaptive_strategy['current_performance']
        
        if performance > 0.6:  # –•–æ—Ä–æ—à–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
            # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä –ø–æ–∑–∏—Ü–∏–∏ –∏ –ø–ª–µ—á–æ
            decision['position_size'] *= 1.1
            decision['leverage'] = min(decision['leverage'] + 1, 20)
        elif performance < 0.4:  # –ü–ª–æ—Ö–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
            # –£–º–µ–Ω—å—à–∞–µ–º —Ä–∞–∑–º–µ—Ä –ø–æ–∑–∏—Ü–∏–∏ –∏ –ø–ª–µ—á–æ
            decision['position_size'] *= 0.9
            decision['leverage'] = max(decision['leverage'] - 1, 1) 